{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "734382a8",
   "metadata": {},
   "source": [
    "# Fully Connected Dense Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "900f46cc-29db-4d85-8fff-292cf3df83f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[config_utils] Could not resolve machine profile from hostname='pcbe15789'. Please set MACHINE env variable to one of: ['mac-andrewxu', 'win-qiyuanxu', 'win-xqiyuan']",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mconfig_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_config\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Configuration\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# config_manager = ConfigManager(load_validated_config(\"SHL_DNN.yaml\"))\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m config_manager = ConfigManager(\u001b[43mload_config\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSHL_DNN.yaml\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m     11\u001b[39m config = config_manager.get()\n\u001b[32m     12\u001b[39m config_manager.add_files(config[\u001b[33m\"\u001b[39m\u001b[33mextra_files\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\xqiyuan\\cernbox\\Documents\\GitHub\\fiber-image-reconstruction-comparison\\config_utils.py:39\u001b[39m, in \u001b[36mload_config\u001b[39m\u001b[34m(exp_name, base_dir)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_config\u001b[39m(exp_name: \u001b[38;5;28mstr\u001b[39m, base_dir: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mconf\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[38;5;28mdict\u001b[39m:\n\u001b[32m     35\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[33;03m    Load + merge base paths, machine profile, and experiment config.\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[33;03m    Returns a fully resolved plain dict (no ${...} left).\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     machine = \u001b[43mdetect_machine\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[config_utils] Using machine profile: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmachine\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     42\u001b[39m     base = OmegaConf.load(Path(base_dir) / \u001b[33m\"\u001b[39m\u001b[33mpaths.yaml\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\xqiyuan\\cernbox\\Documents\\GitHub\\fiber-image-reconstruction-comparison\\config_utils.py:29\u001b[39m, in \u001b[36mdetect_machine\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     26\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m profile\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# 3. Nothing matched -> fail\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     30\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[config_utils] Could not resolve machine profile from hostname=\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     31\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPlease set MACHINE env variable to one of: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(HOST_TO_MACHINE.values())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     32\u001b[39m )\n",
      "\u001b[31mRuntimeError\u001b[39m: [config_utils] Could not resolve machine profile from hostname='pcbe15789'. Please set MACHINE env variable to one of: ['mac-andrewxu', 'win-qiyuanxu', 'win-xqiyuan']"
     ]
    }
   ],
   "source": [
    "# pip install xflow-py\n",
    "from xflow import ConfigManager, FileProvider, PyTorchPipeline, show_model_info\n",
    "from xflow.data import build_transforms_from_config\n",
    "from xflow.trainers import build_callbacks_from_config, build_callbacks_from_config\n",
    "from xflow.utils import load_validated_config, plot_image\n",
    "from config_utils import load_config\n",
    "\n",
    "# Configuration\n",
    "# config_manager = ConfigManager(load_validated_config(\"SHL_DNN.yaml\"))\n",
    "config_manager = ConfigManager(load_config(\"SHL_DNN.yaml\"))\n",
    "config = config_manager.get()\n",
    "config_manager.add_files(config[\"extra_files\"])\n",
    "\n",
    "# Data pipeline\n",
    "provider = FileProvider(config[\"paths\"][\"dataset\"]).subsample(fraction=1, seed=config[\"seed\"])\n",
    "train_provider, temp_provider = provider.split(ratio=config[\"data\"][\"train_val_split\"], \n",
    "                                               seed=config[\"seed\"])\n",
    "val_provider, test_provider = temp_provider.split(ratio=config[\"data\"][\"val_test_split\"], \n",
    "                                                  seed=config[\"seed\"])\n",
    "\n",
    "transforms = build_transforms_from_config(config[\"data\"][\"transforms\"][\"torch\"])\n",
    "\n",
    "def make_dataset(provider):\n",
    "    return PyTorchPipeline(provider, transforms).to_memory_dataset(config[\"data\"][\"dataset_ops\"])\n",
    "\n",
    "train_dataset = make_dataset(train_provider)\n",
    "val_dataset = make_dataset(val_provider)\n",
    "test_dataset = make_dataset(test_provider)\n",
    "\n",
    "print(\"Samples: \",len(train_provider),len(val_provider),len(test_provider))\n",
    "print(\"Batch: \",len(train_dataset),len(val_dataset),len(test_dataset))\n",
    "\n",
    "for left_parts, right_parts in test_dataset:\n",
    "    # batch will be a tuple: (right_halves, left_halves) due to split_width\n",
    "    print(f\"Batch shapes: {left_parts.shape}, {right_parts.shape}\")\n",
    "    plot_image(left_parts[0].reshape(config['data']['input_image_size']))\n",
    "    plot_image(right_parts[0].reshape(config['data']['output_size']))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a933c152",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SHL_DNN import SHLNeuralNetwork\n",
    "\n",
    "# Minimum code to construct the SHL model from config\n",
    "model = SHLNeuralNetwork(\n",
    "    input_size=config['data']['input_image_size'][0] * config['data']['input_image_size'][1],\n",
    "    hidden_size=config['model']['hidden_size'], \n",
    "    output_size=config['data']['output_size'][0] * config['data']['output_size'][1],\n",
    "    dropout_rate=config['model']['dropout_rate']\n",
    ")\n",
    "\n",
    "# Model\n",
    "show_model_info(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b492af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import xflow.extensions.physics\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = torch.nn.MSELoss()  # pixel level MSE\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['training']['learning_rate'])\n",
    "\n",
    "# Callbacks\n",
    "callbacks = build_callbacks_from_config(\n",
    "    config=config[\"callbacks\"],\n",
    "    framework=config[\"framework\"],\n",
    ")\n",
    "callbacks[-1].set_dataset(test_dataset)  # add dataset closure to the last callback\n",
    "\n",
    "# Simple training history tracking\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "# Training loop\n",
    "for cb in callbacks:\n",
    "    cb.on_train_begin(epochs=config['training']['epochs'])  # Pass total epochs\n",
    "\n",
    "for epoch in range(config['training']['epochs']):\n",
    "    for cb in callbacks:\n",
    "        cb.on_epoch_begin(epoch, model=model, total_batches=len(train_dataset))\n",
    "\n",
    "    model.train()\n",
    "    train_loss_sum, n_train = 0.0, 0\n",
    "    \n",
    "    for batch_idx, batch in enumerate(train_dataset):\n",
    "        for cb in callbacks: \n",
    "            cb.on_batch_begin(batch_idx)\n",
    "\n",
    "        inputs, targets = batch\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()                      # 1. clear gradients\n",
    "        outputs = model(inputs)                    # 2. forward pass\n",
    "        loss = criterion(outputs, targets)         # 3. compute loss\n",
    "        loss.backward()                            # 4. backprop\n",
    "        optimizer.step()                           # 5. update weights\n",
    "\n",
    "        # Convert tensor to float for logging\n",
    "        for cb in callbacks:\n",
    "            cb.on_batch_end(batch_idx, logs={\"loss\": loss.item()})\n",
    "\n",
    "        # accumulate for epoch average\n",
    "        train_loss_sum += loss.item()\n",
    "        n_train += 1\n",
    "\n",
    "    avg_train_loss = train_loss_sum / max(1, n_train)\n",
    "\n",
    "    # ----- validation pass (no grad) -----\n",
    "    model.eval()\n",
    "    val_loss_sum, n_val = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for val_inputs, val_targets in val_dataset:     \n",
    "            val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "            val_outputs = model(val_inputs)\n",
    "            val_loss_sum += criterion(val_outputs, val_targets).item()\n",
    "            n_val += 1\n",
    "    avg_val_loss = val_loss_sum / max(1, n_val)\n",
    "\n",
    "    # Save losses to history\n",
    "    train_losses.append(avg_train_loss)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    # Add epoch-level metrics if available\n",
    "    for cb in callbacks:\n",
    "        cb.on_epoch_end(epoch, logs={\n",
    "            \"train_loss\": avg_train_loss,\n",
    "            \"val_loss\": avg_val_loss\n",
    "        })\n",
    "        \n",
    "    # Check for early stopping after all callbacks have run\n",
    "    if any(getattr(cb, 'should_stop', False) for cb in callbacks):\n",
    "        print(\"Early stopping triggered - training stopped.\")\n",
    "        break\n",
    "        \n",
    "# Call once after training\n",
    "for cb in callbacks:\n",
    "    cb.on_train_end()\n",
    "\n",
    "# Save training history (simplest approach)\n",
    "import json\n",
    "with open(f\"{config['paths']['output']}/history.json\", 'w') as f:\n",
    "    json.dump({'train_loss': train_losses, 'val_loss': val_losses}, f)\n",
    "\n",
    "# Save final trained model for inference\n",
    "model.save_model(config[\"paths\"][\"output\"])\n",
    "\n",
    "config_manager.save(output_dir=config[\"paths\"][\"output\"], config_filename=config[\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190a3d5b",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1134f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from xflow.extensions.physics.beam import extract_beam_parameters\n",
    "from SHL_DNN import SHLNeuralNetwork\n",
    "\n",
    "# Load the trained model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = SHLNeuralNetwork.load_model('../SHL-DNN_02/model.pth', device=device)\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "# Clean PyTorch inference - just use forward pass\n",
    "print(\"Testing inference...\")\n",
    "\n",
    "# Get image shapes from config\n",
    "input_shape = config['data']['input_image_size']\n",
    "output_shape = config['data']['output_size']\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataset:\n",
    "        inputs, targets = batch\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        print(f\"Input shape: {inputs.shape}\")\n",
    "        print(f\"Target shape: {targets.shape}\")\n",
    "        \n",
    "        # Pure PyTorch way - same as training!\n",
    "        reconstructed_images = model(inputs)\n",
    "        print(f\"Reconstructed shape: {reconstructed_images.shape}\")\n",
    "        \n",
    "        # Plot first sample, reshaped to square images\n",
    "        plot_image(inputs[0].reshape(input_shape), title=\"Input\")\n",
    "        plot_image(reconstructed_images[0].reshape(output_shape), title=\"Reconstructed\")\n",
    "        plot_image(targets[0].reshape(output_shape), title=\"Ground Truth\")\n",
    "        \n",
    "        # Only process first batch for testing\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
