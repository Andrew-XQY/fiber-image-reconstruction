{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bed5cdf6",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79336363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/andrewxu/Documents/GitHub/fiber-image-reconstruction\n",
      "[config_utils] Using machine profile: mac-andrewxu\n",
      "[config_utils] Using machine profile: mac-andrewxu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "os.chdir(Path.cwd().parent)   # go one level up\n",
    "print(os.getcwd())            # check\n",
    "\n",
    "# pip install xflow-py\n",
    "from xflow import ConfigManager, SqlProvider, PyTorchPipeline, show_model_info\n",
    "from xflow.data import build_transforms_from_config\n",
    "from xflow.utils import load_validated_config, save_image\n",
    "import xflow.extensions.physics\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import tarfile\n",
    "from datetime import datetime  \n",
    "from config_utils import load_config\n",
    "from utils import *\n",
    "\n",
    "\n",
    "# Create experiment output directory  (timestamped)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")  \n",
    "\n",
    "experiment_name = \"CAE_validate_clear\"  # TM, SHL_DNN, U_Net, Pix2pix, ERN, CAE, SwinT, CAE_syth\n",
    "model_name = \"CAE\"\n",
    "folder_name = f\"{experiment_name}-{timestamp}\"  \n",
    "config_manager = ConfigManager(load_config(f\"{experiment_name}.yaml\", \n",
    "                                           experiment_name=folder_name))\n",
    "config = config_manager.get()\n",
    "config_manager.add_files(config[\"extra_files\"])\n",
    "\n",
    "experiment_output_dir = config[\"paths\"][\"output\"]\n",
    "os.makedirs(experiment_output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# New structure, read the database table first, get files from it.\n",
    "# Extract tar file if needed\n",
    "if config['file_extract']:\n",
    "    dataset_tar_file = os.path.join(config[\"paths\"][\"dataset\"], config[\"data\"][\"dataset\"])\n",
    "    dataset_base_dir = os.path.dirname(dataset_tar_file)\n",
    "    dataset_name = os.path.splitext(config[\"data\"][\"dataset\"])[0]  # Remove .tar extension\n",
    "    dataset_extracted_dir = os.path.join(dataset_base_dir, dataset_name)\n",
    "\n",
    "    # Unzip tar file if not already extracted\n",
    "    if not os.path.exists(dataset_extracted_dir):\n",
    "        print(f\"Extracting {dataset_tar_file}...\")\n",
    "        with tarfile.open(dataset_tar_file, 'r') as tar:\n",
    "            tar.extractall(path=dataset_base_dir)\n",
    "        print(f\"Extracted to {dataset_extracted_dir}\")\n",
    "    else:\n",
    "        print(f\"Dataset already extracted at {dataset_extracted_dir}\")\n",
    "        \n",
    "\n",
    "def make_dataset(provider, transforms):\n",
    "    pipeline = PyTorchPipeline(provider, transforms)\n",
    "    dataset = pipeline.to_memory_dataset(config[\"data\"][\"dataset_ops\"])\n",
    "    return dataset, pipeline.in_memory_sample_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3434c04d",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ad0ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== \n",
    "# Prepare Dataset (Laser scan + YAG screen )\n",
    "# ====================\n",
    "train_dir = config[\"paths\"][\"training_set\"]\n",
    "# Create SqlProvider to query the database\n",
    "db_path = f\"{train_dir}/db/dataset_meta.db\"\n",
    "query = \"\"\" \n",
    "SELECT \n",
    "    image_path\n",
    "FROM mmf_dataset_metadata \n",
    "WHERE batch IN (15)\n",
    "--LIMIT 300\n",
    "\"\"\"\n",
    "train_provider = SqlProvider(\n",
    "    sources={\"connection\": db_path, \"sql\": query}, output_config={'list': \"image_path\"}\n",
    ")\n",
    "\n",
    "test_dir = config[\"paths\"][\"test_set\"]\n",
    "# Create SqlProvider to query the database\n",
    "db_path = f\"{test_dir}/db/dataset_meta.db\"\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    image_path\n",
    "FROM mmf_dataset_metadata \n",
    "WHERE batch IN (1, 7)\n",
    "--LIMIT 20\n",
    "\"\"\"\n",
    "evaluation_provider = SqlProvider(\n",
    "    sources={\"connection\": db_path, \"sql\": query}, output_config={'list': \"image_path\"}\n",
    ")\n",
    "val_provider, test_provider = evaluation_provider.split(ratio=config[\"data\"][\"val_test_split\"], seed=config[\"seed\"])\n",
    "\n",
    "# Swap traing dataset and evaluation dataset\n",
    "train_dir, test_dir = test_dir, train_dir\n",
    "train_provider, evaluation_provider = evaluation_provider, train_provider\n",
    "val_provider, test_provider = evaluation_provider.split(ratio=config[\"data\"][\"val_test_split\"], seed=config[\"seed\"])\n",
    "\n",
    "# For train dataset\n",
    "config[\"data\"][\"transforms\"][\"torch\"].insert(0, {\n",
    "    \"name\": \"add_parent_dir\",\n",
    "    \"params\": {\n",
    "        \"parent_dir\": train_dir\n",
    "    }\n",
    "})\n",
    "transforms = build_transforms_from_config(config[\"data\"][\"transforms\"][\"torch\"])\n",
    "train_datase, n1 = make_dataset(train_provider, transforms)\n",
    "\n",
    "# For test datasets\n",
    "config[\"data\"][\"transforms\"][\"torch\"][0][\"params\"][\"parent_dir\"] = test_dir\n",
    "transforms = build_transforms_from_config(config[\"data\"][\"transforms\"][\"torch\"])\n",
    "val_dataset, n2 = make_dataset(val_provider, transforms)\n",
    "test_dataset, n3 = make_dataset(test_provider, transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0115b202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== \n",
    "# Prepare Dataset (YAG screen)\n",
    "# ====================\n",
    "\n",
    "test_dir = config[\"paths\"][\"test_set\"]\n",
    "# Create SqlProvider to query the database\n",
    "db_path = f\"{test_dir}/db/dataset_meta.db\"\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    image_path\n",
    "FROM mmf_dataset_metadata \n",
    "WHERE batch IN (1, 7)\n",
    "--LIMIT 20\n",
    "\"\"\"\n",
    "realbeam_provider = SqlProvider(\n",
    "    sources={\"connection\": db_path, \"sql\": query}, output_config={'list': \"image_path\"}\n",
    ")\n",
    "train_provider, evaluation_provider = realbeam_provider.split(ratio=config[\"data\"][\"train_val_split\"], seed=config[\"seed\"])\n",
    "val_provider, test_provider = evaluation_provider.split(ratio=config[\"data\"][\"val_test_split\"], seed=config[\"seed\"])\n",
    "\n",
    "# For train dataset\n",
    "config[\"data\"][\"transforms\"][\"torch\"].insert(0, {\n",
    "    \"name\": \"add_parent_dir\",\n",
    "    \"params\": {\n",
    "        \"parent_dir\": test_dir\n",
    "    }\n",
    "})\n",
    "transforms = build_transforms_from_config(config[\"data\"][\"transforms\"][\"torch\"])\n",
    "train_dataset, n1 = make_dataset(train_provider, transforms)\n",
    "val_dataset, n2 = make_dataset(val_provider, transforms)\n",
    "test_dataset, n3 = make_dataset(test_provider, transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be06a2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d10125daaf3473da7f46972d8f14444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading data into memory:   0%|          | 0/263 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to preprocess item: Centroid (143.6953582763672, 181.52749633789062) outside rectangle bounds\n",
      "Failed to preprocess item: Centroid (140.02857971191406, 92.65306091308594) outside rectangle bounds\n",
      "Failed to preprocess item: Centroid (115.63353729248047, 185.60708618164062) outside rectangle bounds\n",
      "Failed to preprocess item: Centroid (129.43499755859375, 89.33609008789062) outside rectangle bounds\n",
      "Failed to preprocess item: Centroid (140.02857971191406, 92.65306091308594) outside rectangle bounds\n",
      "Failed to preprocess item: Centroid (115.63353729248047, 185.60708618164062) outside rectangle bounds\n",
      "Failed to preprocess item: Centroid (129.43499755859375, 89.33609008789062) outside rectangle bounds\n",
      "Failed to preprocess item: Centroid (142.36422729492188, 87.2079849243164) outside rectangle bounds\n",
      "Failed to preprocess item: Centroid (142.36422729492188, 87.2079849243164) outside rectangle bounds\n",
      "Failed to preprocess item: Centroid (143.44810485839844, 85.41702270507812) outside rectangle bounds\n",
      "Failed to preprocess item: Centroid (149.2236785888672, 100.35179138183594) outside rectangle bounds\n",
      "Failed to preprocess item: Centroid (143.44810485839844, 85.41702270507812) outside rectangle bounds\n",
      "Failed to preprocess item: Centroid (149.2236785888672, 100.35179138183594) outside rectangle bounds\n",
      "Failed to preprocess item: Centroid (135.32131958007812, 94.82951354980469) outside rectangle bounds\n",
      "Failed to preprocess item: Centroid (135.32131958007812, 94.82951354980469) outside rectangle bounds\n",
      "Failed to preprocess item: Centroid (148.1605682373047, 99.27643585205078) outside rectangle bounds\n",
      "Failed to preprocess item: Centroid (148.1605682373047, 99.27643585205078) outside rectangle bounds\n",
      "Failed to preprocess item: Centroid (118.70569610595703, 180.9061279296875) outside rectangle bounds\n",
      "Failed to preprocess item: Centroid (118.70569610595703, 180.9061279296875) outside rectangle bounds\n",
      "Failed to preprocess item: Centroid (130.752685546875, 92.60176849365234) outside rectangle bounds\n",
      "Failed to preprocess item: Centroid (147.0064239501953, 100.01714324951172) outside rectangle bounds\n",
      "Failed to preprocess item: Centroid (130.752685546875, 92.60176849365234) outside rectangle bounds\n",
      "Failed to preprocess item: Centroid (147.0064239501953, 100.01714324951172) outside rectangle bounds\n",
      "Failed to preprocess item: Centroid (145.66600036621094, 84.41515350341797) outside rectangle bounds\n",
      "Failed to preprocess item: Centroid (145.66600036621094, 84.41515350341797) outside rectangle bounds\n",
      "Failed to preprocess item: Centroid (135.2174835205078, 183.25704956054688) outside rectangle bounds\n",
      "Failed to preprocess item: Centroid (135.2174835205078, 183.25704956054688) outside rectangle bounds\n",
      "Failed to preprocess item: Centroid (119.87644958496094, 184.6299285888672) outside rectangle bounds\n",
      "Failed to preprocess item: Centroid (119.87644958496094, 184.6299285888672) outside rectangle bounds\n"
     ]
    }
   ],
   "source": [
    "# ==================== \n",
    "# Prepare Dataset (Wednesday Chromox)\n",
    "# ====================\n",
    "\n",
    "test_dir = config[\"paths\"][\"chromox_01\"]\n",
    "# Create SqlProvider to query the database\n",
    "db_path = f\"{test_dir}/db/dataset_meta.db\"\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    image_path\n",
    "FROM mmf_dataset_metadata \n",
    "WHERE batch IN (10, 11, 12)\n",
    "--LIMIT 20\n",
    "\"\"\"\n",
    "realbeam_provider = SqlProvider(\n",
    "    sources={\"connection\": db_path, \"sql\": query}, output_config={'list': \"image_path\"}\n",
    ")\n",
    "train_provider, evaluation_provider = realbeam_provider.split(ratio=config[\"data\"][\"train_val_split\"], seed=config[\"seed\"])\n",
    "val_provider, test_provider = evaluation_provider.split(ratio=config[\"data\"][\"val_test_split\"], seed=config[\"seed\"])\n",
    "\n",
    "# For train dataset\n",
    "config[\"data\"][\"transforms\"][\"torch\"].insert(0, {\n",
    "    \"name\": \"add_parent_dir\",\n",
    "    \"params\": {\n",
    "        \"parent_dir\": test_dir\n",
    "    }\n",
    "})\n",
    "transforms = build_transforms_from_config(config[\"data\"][\"transforms\"][\"torch\"])\n",
    "train_dataset, n1 = make_dataset(train_provider, transforms)\n",
    "val_dataset, n2 = make_dataset(val_provider, transforms)\n",
    "test_dataset, n3 = make_dataset(test_provider, transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78860ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== \n",
    "# Prepare Dataset (Friday + Saturday Chromox)\n",
    "# ====================\n",
    "\n",
    "test_dir = config[\"paths\"][\"\"]\n",
    "# Create SqlProvider to query the database\n",
    "db_path = f\"{test_dir}/db/dataset_meta.db\"\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    image_path\n",
    "FROM mmf_dataset_metadata \n",
    "WHERE batch IN (10, 11, 12)\n",
    "--LIMIT 20\n",
    "\"\"\"\n",
    "realbeam_provider = SqlProvider(\n",
    "    sources={\"connection\": db_path, \"sql\": query}, output_config={'list': \"image_path\"}\n",
    ")\n",
    "train_provider, evaluation_provider = realbeam_provider.split(ratio=config[\"data\"][\"train_val_split\"], seed=config[\"seed\"])\n",
    "val_provider, test_provider = evaluation_provider.split(ratio=config[\"data\"][\"val_test_split\"], seed=config[\"seed\"])\n",
    "\n",
    "# For train dataset\n",
    "config[\"data\"][\"transforms\"][\"torch\"].insert(0, {\n",
    "    \"name\": \"add_parent_dir\",\n",
    "    \"params\": {\n",
    "        \"parent_dir\": test_dir\n",
    "    }\n",
    "})\n",
    "transforms = build_transforms_from_config(config[\"data\"][\"transforms\"][\"torch\"])\n",
    "train_dataset, n1 = make_dataset(train_provider, transforms)\n",
    "val_dataset, n2 = make_dataset(val_provider, transforms)\n",
    "test_dataset, n3 = make_dataset(test_provider, transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe32b5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples in providers:  2101 263 263\n",
      "Total samples in datasets: 1939 245 248\n",
      "Batch:  61 8 8\n",
      "Batch shapes: torch.Size([32, 1, 256, 256]), torch.Size([32, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Total samples in providers: \",len(train_provider),len(val_provider),len(test_provider))\n",
    "print(\"Total samples in datasets:\", n1, n2, n3)\n",
    "print(\"Batch: \",len(train_dataset),len(val_dataset),len(test_dataset))\n",
    "\n",
    "# save a sample from dataset for debugging\n",
    "if model_name in REGRESSION:\n",
    "    for left_parts, params, right_parts in test_dataset:\n",
    "        print(f\"Batch shapes: {left_parts.shape}, {right_parts.shape}\")\n",
    "        save_image(left_parts[0], config[\"paths\"][\"output\"] + \"/input.png\")\n",
    "        save_image(right_parts[0], config[\"paths\"][\"output\"] + \"/output.png\")\n",
    "        break\n",
    "else:\n",
    "    for index, sample in enumerate(test_dataset):  # test_dataset\n",
    "        left_parts, right_parts = sample\n",
    "        # batch will be a tuple: (right_halves, left_halves) due to split_width\n",
    "        print(f\"Batch shapes: {left_parts.shape}, {right_parts.shape}\")\n",
    "        if model_name in SAMPLE_FLATTENED:\n",
    "            save_image(left_parts[0].reshape(config['data']['input_shape']), config[\"paths\"][\"output\"] + f\"/input_{index}.png\")\n",
    "            save_image(right_parts[0].reshape(config['data']['output_shape']), config[\"paths\"][\"output\"] + f\"/output_{index}.png\")\n",
    "        else:\n",
    "            save_image(left_parts[0], config[\"paths\"][\"output\"] + f\"/input_{index}.png\")\n",
    "            save_image(right_parts[0], config[\"paths\"][\"output\"] + f\"/output_{index}.png\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f436c74c",
   "metadata": {},
   "source": [
    "# Construct Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c745409a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected framework: PyTorch\n",
      "Framework:           PyTorch\n",
      "Model:               Autoencoder2D\n",
      "Device / dtype:      unavailable / N/A\n",
      "Parameters:          18,620,544 total\n",
      "                     18,620,544 trainable\n",
      "                     0 non-trainable\n",
      "Size:                71.06 MB\n",
      "Sub-modules:         67\n"
     ]
    }
   ],
   "source": [
    "# ==================== \n",
    "# Construct Model\n",
    "# ====================\n",
    "if model_name == \"CAE\":\n",
    "    from models.CAE import Autoencoder2D\n",
    "    model = Autoencoder2D(\n",
    "        in_channels=int(config['model'][\"in_channels\"]),\n",
    "        encoder=config['model'][\"encoder\"],\n",
    "        decoder=config['model'][\"decoder\"],\n",
    "        kernel_size=int(config['model'][\"kernel_size\"]),\n",
    "        apply_batchnorm=config['model'][\"apply_batchnorm\"],\n",
    "        apply_dropout=config['model'][\"apply_dropout\"],\n",
    "        final_activation=str(config['model'][\"final_activation\"]),\n",
    "    )\n",
    "elif model_name == \"TM\":\n",
    "    from models.TM import TransmissionMatrix\n",
    "    model = TransmissionMatrix(\n",
    "        input_height = config[\"data\"][\"input_shape\"][0],\n",
    "        input_width = config[\"data\"][\"input_shape\"][1],\n",
    "        output_height = config[\"data\"][\"output_shape\"][0],\n",
    "        output_width = config[\"data\"][\"output_shape\"][1],\n",
    "        initialization = \"xavier\",\n",
    "    )\n",
    "elif model_name == \"SHL_DNN\":\n",
    "    from models.SHL_DNN import SHLNeuralNetwork\n",
    "    model = SHLNeuralNetwork(\n",
    "        input_size=config['data']['input_shape'][0] * config['data']['input_shape'][1],\n",
    "        hidden_size=config['model']['hidden_size'], \n",
    "        output_size=config['data']['output_shape'][0] * config['data']['output_shape'][1],\n",
    "        dropout_rate=config['model']['dropout_rate'],\n",
    "    )\n",
    "elif model_name == \"U_Net\":\n",
    "    from models.U_Net import UNet\n",
    "    model = UNet(\n",
    "        in_channels=config[\"model\"][\"in_channels\"],\n",
    "        encoder=config[\"model\"][\"encoder\"],\n",
    "        decoder=config[\"model\"][\"decoder\"],\n",
    "        kernel_size=config[\"model\"][\"kernel_size\"],\n",
    "        apply_batchnorm=config[\"model\"][\"apply_batchnorm\"],\n",
    "        apply_dropout=config[\"model\"][\"apply_dropout\"],\n",
    "        out_channels=config[\"model\"][\"out_channels\"],\n",
    "        final_activation=config[\"model\"][\"final_activation\"],\n",
    "    )\n",
    "elif model_name == \"SwinT\":\n",
    "    from models.SwinT import SwinUNet, ReconLoss\n",
    "    model = SwinUNet(\n",
    "        img_size=config['model']['img_size'],\n",
    "        in_chans=config['model']['in_chans'],\n",
    "        out_chans=config['model']['out_chans'],\n",
    "        embed_dim=config['model']['embed_dim'],\n",
    "        depths=config['model']['depths'],\n",
    "        num_heads=config['model']['num_heads'],\n",
    "        window_size=config['model']['window_size'],\n",
    "        patch_size=config['model']['patch_size'],\n",
    "    )\n",
    "elif model_name == \"Pix2pix\":\n",
    "    from models.Pix2pix import Generator, Discriminator, Pix2PixLosses\n",
    "    G = Generator(channels=config[\"model\"][\"channels\"])\n",
    "    D = Discriminator(channels=config[\"model\"][\"channels\"])\n",
    "    losses = Pix2PixLosses(lambda_l1=config[\"model\"][\"lambda_l1\"])\n",
    "    opt_g = torch.optim.Adam(G.parameters(), lr=config[\"training\"][\"learning_rate\"], betas=config[\"training\"][\"betas\"])\n",
    "    opt_d = torch.optim.Adam(D.parameters(), lr=config[\"training\"][\"learning_rate\"], betas=config[\"training\"][\"betas\"])\n",
    "elif model_name == \"ERN\":\n",
    "    from models.ERN import EncoderRegressor\n",
    "    model = EncoderRegressor(\n",
    "            in_channels=config['model']['in_channels'],\n",
    "            kernel_size=config['model']['kernel_size'],\n",
    "            encoder=config['model']['encoder'],\n",
    "            decoder=config['model']['decoder'],\n",
    "            final_activation=config['model']['final_activation'],  \n",
    "        )\n",
    "elif model_name == \"CAE_syth\":\n",
    "    from models.CAE import Autoencoder2D\n",
    "    model = Autoencoder2D(\n",
    "        in_channels=int(config['model'][\"in_channels\"]),\n",
    "        encoder=config['model'][\"encoder\"],\n",
    "        decoder=config['model'][\"decoder\"],\n",
    "        kernel_size=int(config['model'][\"kernel_size\"]),\n",
    "        apply_batchnorm=config['model'][\"apply_batchnorm\"],\n",
    "        apply_dropout=config['model'][\"apply_dropout\"],\n",
    "        final_activation=str(config['model'][\"final_activation\"]),\n",
    "    )\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "if model_name == \"Pix2pix\":\n",
    "    G = G.to(device)\n",
    "    D = D.to(device)\n",
    "    show_model_info(G)\n",
    "    show_model_info(D)\n",
    "elif model_name == \"SwinT\":\n",
    "    from torch.optim.lr_scheduler import LambdaLR\n",
    "    total_steps = config['training']['epochs'] * len(train_dataset)\n",
    "    warmup_steps = int(config['training']['warmup_ratio'] * total_steps)\n",
    "    def lr_lambda(step):\n",
    "        if step < warmup_steps:\n",
    "            return (step + 1) / max(1, warmup_steps)\n",
    "        t = (step - warmup_steps) / max(1, total_steps - warmup_steps)\n",
    "        return 0.5 * (1.0 + math.cos(math.pi * t))\n",
    "\n",
    "    model = model.to(device)\n",
    "    criterion = ReconLoss(w_l1=config['training']['w_l1'], w_ssim=config['training']['w_ssim']) # Loss: L1 + 0.3*SSIM\n",
    "\n",
    "    # Optimizer: AdamW with recommended params\n",
    "    base_lr = 4e-4 if config['training']['batch_size'] >= 64 else 2e-4\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=base_lr, betas=config['training']['betas'],\n",
    "        eps=config['training']['eps'], weight_decay=config['training']['weight_decay']\n",
    "    )\n",
    "    scheduler = LambdaLR(optimizer, lr_lambda)\n",
    "    show_model_info(model)\n",
    "else:\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['training']['learning_rate'])\n",
    "    show_model_info(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "248a65cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "Total epochs: 100\n",
      "\n",
      "Epoch 1/100 - 61 batches\n",
      "input image max pixel: 0.1098, ground truth image max pixel: 0.2063, reconstructed image max pixel: 0.5000\n",
      "input image max pixel: 0.1098, ground truth image max pixel: 0.2063, reconstructed image max pixel: 0.5000\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0868 - val_loss: 0.0198                      \n",
      "Epoch 1 completed in 561.89s - train_loss: 0.0868 - val_loss: 0.0198\n",
      "\n",
      "Epoch 2/100 - 61 batches\n",
      "\n",
      "Epoch 1 completed in 561.89s - train_loss: 0.0868 - val_loss: 0.0198\n",
      "\n",
      "Epoch 2/100 - 61 batches\n",
      "input image max pixel: 0.4579, ground truth image max pixel: 0.1765, reconstructed image max pixel: 0.4237\n",
      "input image max pixel: 0.4579, ground truth image max pixel: 0.1765, reconstructed image max pixel: 0.4237\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0103 - val_loss: 0.0068                      \n",
      "Epoch 2 completed in 557.56s - train_loss: 0.0103 - val_loss: 0.0068\n",
      "\n",
      "Epoch 3/100 - 61 batches\n",
      "\n",
      "Epoch 2 completed in 557.56s - train_loss: 0.0103 - val_loss: 0.0068\n",
      "\n",
      "Epoch 3/100 - 61 batches\n",
      "input image max pixel: 0.1373, ground truth image max pixel: 0.8568, reconstructed image max pixel: 0.3343\n",
      "input image max pixel: 0.1373, ground truth image max pixel: 0.8568, reconstructed image max pixel: 0.3343\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0051 - val_loss: 0.0041                      \n",
      "Epoch 3 completed in 558.78s - train_loss: 0.0051 - val_loss: 0.0041\n",
      "\n",
      "Epoch 4/100 - 61 batches\n",
      "\n",
      "Epoch 3 completed in 558.78s - train_loss: 0.0051 - val_loss: 0.0041\n",
      "\n",
      "Epoch 4/100 - 61 batches\n",
      "input image max pixel: 0.1229, ground truth image max pixel: 0.1529, reconstructed image max pixel: 0.2705\n",
      "input image max pixel: 0.1229, ground truth image max pixel: 0.1529, reconstructed image max pixel: 0.2705\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0036 - val_loss: 0.0032                      \n",
      "Epoch 4 completed in 580.10s - train_loss: 0.0036 - val_loss: 0.0032\n",
      "\n",
      "Epoch 5/100 - 61 batches\n",
      "\n",
      "Epoch 4 completed in 580.10s - train_loss: 0.0036 - val_loss: 0.0032\n",
      "\n",
      "Epoch 5/100 - 61 batches\n",
      "input image max pixel: 0.3569, ground truth image max pixel: 0.1327, reconstructed image max pixel: 0.2266\n",
      "input image max pixel: 0.3569, ground truth image max pixel: 0.1327, reconstructed image max pixel: 0.2266\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0029 - val_loss: 0.0026                      \n",
      "Epoch 5 completed in 568.13s - train_loss: 0.0029 - val_loss: 0.0026\n",
      "\n",
      "Epoch 6/100 - 61 batches\n",
      "\n",
      "Epoch 5 completed in 568.13s - train_loss: 0.0029 - val_loss: 0.0026\n",
      "\n",
      "Epoch 6/100 - 61 batches\n",
      "input image max pixel: 0.0902, ground truth image max pixel: 0.0314, reconstructed image max pixel: 0.1946\n",
      "input image max pixel: 0.0902, ground truth image max pixel: 0.0314, reconstructed image max pixel: 0.1946\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0026 - val_loss: 0.0024                      \n",
      "Epoch 6 completed in 553.75s - train_loss: 0.0026 - val_loss: 0.0024\n",
      "\n",
      "Epoch 7/100 - 61 batches\n",
      "\n",
      "Epoch 6 completed in 553.75s - train_loss: 0.0026 - val_loss: 0.0024\n",
      "\n",
      "Epoch 7/100 - 61 batches\n",
      "input image max pixel: 0.4768, ground truth image max pixel: 0.3931, reconstructed image max pixel: 0.1675\n",
      "input image max pixel: 0.4768, ground truth image max pixel: 0.3931, reconstructed image max pixel: 0.1675\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0024 - val_loss: 0.0022                      \n",
      "Epoch 7 completed in 568.20s - train_loss: 0.0024 - val_loss: 0.0022\n",
      "\n",
      "Epoch 8/100 - 61 batches\n",
      "\n",
      "Epoch 7 completed in 568.20s - train_loss: 0.0024 - val_loss: 0.0022\n",
      "\n",
      "Epoch 8/100 - 61 batches\n",
      "input image max pixel: 0.2824, ground truth image max pixel: 0.0980, reconstructed image max pixel: 0.1512\n",
      "input image max pixel: 0.2824, ground truth image max pixel: 0.0980, reconstructed image max pixel: 0.1512\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0022 - val_loss: 0.0020                      \n",
      "Epoch 8 completed in 555.77s - train_loss: 0.0022 - val_loss: 0.0020\n",
      "\n",
      "Epoch 9/100 - 61 batches\n",
      "\n",
      "Epoch 8 completed in 555.77s - train_loss: 0.0022 - val_loss: 0.0020\n",
      "\n",
      "Epoch 9/100 - 61 batches\n",
      "input image max pixel: 0.2353, ground truth image max pixel: 0.4841, reconstructed image max pixel: 0.1389\n",
      "input image max pixel: 0.2353, ground truth image max pixel: 0.4841, reconstructed image max pixel: 0.1389\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0021 - val_loss: 0.0020                      \n",
      "Epoch 9 completed in 553.56s - train_loss: 0.0021 - val_loss: 0.0020\n",
      "\n",
      "Epoch 10/100 - 61 batches\n",
      "\n",
      "Epoch 9 completed in 553.56s - train_loss: 0.0021 - val_loss: 0.0020\n",
      "\n",
      "Epoch 10/100 - 61 batches\n",
      "input image max pixel: 0.1804, ground truth image max pixel: 0.3268, reconstructed image max pixel: 0.1301\n",
      "input image max pixel: 0.1804, ground truth image max pixel: 0.3268, reconstructed image max pixel: 0.1301\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0021 - val_loss: 0.0019                      \n",
      "Epoch 10 completed in 552.86s - train_loss: 0.0021 - val_loss: 0.0019\n",
      "\n",
      "Epoch 11/100 - 61 batches\n",
      "\n",
      "Epoch 10 completed in 552.86s - train_loss: 0.0021 - val_loss: 0.0019\n",
      "\n",
      "Epoch 11/100 - 61 batches\n",
      "input image max pixel: 0.3725, ground truth image max pixel: 0.5817, reconstructed image max pixel: 0.1247\n",
      "input image max pixel: 0.3725, ground truth image max pixel: 0.5817, reconstructed image max pixel: 0.1247\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0020 - val_loss: 0.0019                      \n",
      "Epoch 11 completed in 556.84s - train_loss: 0.0020 - val_loss: 0.0019\n",
      "\n",
      "Epoch 12/100 - 61 batches\n",
      "\n",
      "Epoch 11 completed in 556.84s - train_loss: 0.0020 - val_loss: 0.0019\n",
      "\n",
      "Epoch 12/100 - 61 batches\n",
      "input image max pixel: 0.1490, ground truth image max pixel: 0.0784, reconstructed image max pixel: 0.1167\n",
      "input image max pixel: 0.1490, ground truth image max pixel: 0.0784, reconstructed image max pixel: 0.1167\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0020 - val_loss: 0.0019                      \n",
      "Epoch 12 completed in 560.79s - train_loss: 0.0020 - val_loss: 0.0019\n",
      "\n",
      "Epoch 13/100 - 61 batches\n",
      "\n",
      "Epoch 12 completed in 560.79s - train_loss: 0.0020 - val_loss: 0.0019\n",
      "\n",
      "Epoch 13/100 - 61 batches\n",
      "input image max pixel: 0.4992, ground truth image max pixel: 0.6283, reconstructed image max pixel: 0.1079\n",
      "input image max pixel: 0.4992, ground truth image max pixel: 0.6283, reconstructed image max pixel: 0.1079\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0019 - val_loss: 0.0018                      \n",
      "Epoch 13 completed in 574.83s - train_loss: 0.0019 - val_loss: 0.0018\n",
      "\n",
      "Epoch 14/100 - 61 batches\n",
      "\n",
      "Epoch 13 completed in 574.83s - train_loss: 0.0019 - val_loss: 0.0018\n",
      "\n",
      "Epoch 14/100 - 61 batches\n",
      "input image max pixel: 0.2118, ground truth image max pixel: 0.1089, reconstructed image max pixel: 0.1028\n",
      "input image max pixel: 0.2118, ground truth image max pixel: 0.1089, reconstructed image max pixel: 0.1028\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0019 - val_loss: 0.0018                      \n",
      "Epoch 14 completed in 551.44s - train_loss: 0.0019 - val_loss: 0.0018\n",
      "\n",
      "Epoch 15/100 - 61 batches\n",
      "\n",
      "Epoch 14 completed in 551.44s - train_loss: 0.0019 - val_loss: 0.0018\n",
      "\n",
      "Epoch 15/100 - 61 batches\n",
      "input image max pixel: 0.3216, ground truth image max pixel: 0.0901, reconstructed image max pixel: 0.1015\n",
      "input image max pixel: 0.3216, ground truth image max pixel: 0.0901, reconstructed image max pixel: 0.1015\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0019 - val_loss: 0.0017                      \n",
      "Epoch 15 completed in 577.58s - train_loss: 0.0019 - val_loss: 0.0017\n",
      "\n",
      "Epoch 16/100 - 61 batches\n",
      "\n",
      "Epoch 15 completed in 577.58s - train_loss: 0.0019 - val_loss: 0.0017\n",
      "\n",
      "Epoch 16/100 - 61 batches\n",
      "input image max pixel: 0.1216, ground truth image max pixel: 0.0116, reconstructed image max pixel: 0.0960\n",
      "input image max pixel: 0.1216, ground truth image max pixel: 0.0116, reconstructed image max pixel: 0.0960\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0018 - val_loss: 0.0017                      \n",
      "Epoch 16 completed in 597.77s - train_loss: 0.0018 - val_loss: 0.0017\n",
      "\n",
      "Epoch 17/100 - 61 batches\n",
      "\n",
      "Epoch 16 completed in 597.77s - train_loss: 0.0018 - val_loss: 0.0017\n",
      "\n",
      "Epoch 17/100 - 61 batches\n",
      "input image max pixel: 0.1333, ground truth image max pixel: 0.1560, reconstructed image max pixel: 0.1008\n",
      "input image max pixel: 0.1333, ground truth image max pixel: 0.1560, reconstructed image max pixel: 0.1008\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0017 - val_loss: 0.0016                      \n",
      "Epoch 17 completed in 574.17s - train_loss: 0.0017 - val_loss: 0.0016\n",
      "\n",
      "Epoch 18/100 - 61 batches\n",
      "\n",
      "Epoch 17 completed in 574.17s - train_loss: 0.0017 - val_loss: 0.0016\n",
      "\n",
      "Epoch 18/100 - 61 batches\n",
      "input image max pixel: 0.0902, ground truth image max pixel: 0.0118, reconstructed image max pixel: 0.0972\n",
      "input image max pixel: 0.0902, ground truth image max pixel: 0.0118, reconstructed image max pixel: 0.0972\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0017 - val_loss: 0.0015                      \n",
      "Epoch 18 completed in 549.81s - train_loss: 0.0017 - val_loss: 0.0015\n",
      "\n",
      "Epoch 19/100 - 61 batches\n",
      "\n",
      "Epoch 18 completed in 549.81s - train_loss: 0.0017 - val_loss: 0.0015\n",
      "\n",
      "Epoch 19/100 - 61 batches\n",
      "input image max pixel: 0.0784, ground truth image max pixel: 0.3095, reconstructed image max pixel: 0.1016\n",
      "input image max pixel: 0.0784, ground truth image max pixel: 0.3095, reconstructed image max pixel: 0.1016\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0016 - val_loss: 0.0014                      \n",
      "Epoch 19 completed in 549.96s - train_loss: 0.0016 - val_loss: 0.0014\n",
      "\n",
      "Epoch 20/100 - 61 batches\n",
      "\n",
      "Epoch 19 completed in 549.96s - train_loss: 0.0016 - val_loss: 0.0014\n",
      "\n",
      "Epoch 20/100 - 61 batches\n",
      "input image max pixel: 0.0392, ground truth image max pixel: 0.0078, reconstructed image max pixel: 0.1017\n",
      "input image max pixel: 0.0392, ground truth image max pixel: 0.0078, reconstructed image max pixel: 0.1017\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0016 - val_loss: 0.0014                      \n",
      "Epoch 20 completed in 545.11s - train_loss: 0.0016 - val_loss: 0.0014\n",
      "\n",
      "Epoch 21/100 - 61 batches\n",
      "\n",
      "Epoch 20 completed in 545.11s - train_loss: 0.0016 - val_loss: 0.0014\n",
      "\n",
      "Epoch 21/100 - 61 batches\n",
      "input image max pixel: 0.4353, ground truth image max pixel: 0.8061, reconstructed image max pixel: 0.4079\n",
      "input image max pixel: 0.4353, ground truth image max pixel: 0.8061, reconstructed image max pixel: 0.4079\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0015 - val_loss: 0.0015                      \n",
      "Epoch 21 completed in 561.00s - train_loss: 0.0015 - val_loss: 0.0015\n",
      "\n",
      "Epoch 22/100 - 61 batches\n",
      "\n",
      "Epoch 21 completed in 561.00s - train_loss: 0.0015 - val_loss: 0.0015\n",
      "\n",
      "Epoch 22/100 - 61 batches\n",
      "input image max pixel: 0.1011, ground truth image max pixel: 0.0309, reconstructed image max pixel: 0.0966\n",
      "input image max pixel: 0.1011, ground truth image max pixel: 0.0309, reconstructed image max pixel: 0.0966\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0015 - val_loss: 0.0015                      \n",
      "Epoch 22 completed in 556.52s - train_loss: 0.0015 - val_loss: 0.0015\n",
      "\n",
      "Epoch 23/100 - 61 batches\n",
      "input image max pixel: 0.5020, ground truth image max pixel: 0.5510, reconstructed image max pixel: 0.1437\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0014 - val_loss: 0.0013                      \n",
      "Epoch 23 completed in 580.64s - train_loss: 0.0014 - val_loss: 0.0013\n",
      "\n",
      "Epoch 24/100 - 61 batches\n",
      "input image max pixel: 0.0745, ground truth image max pixel: 0.3221, reconstructed image max pixel: 0.1025\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0013 - val_loss: 0.0012                      \n",
      "Epoch 24 completed in 554.41s - train_loss: 0.0013 - val_loss: 0.0012\n",
      "\n",
      "Epoch 25/100 - 61 batches\n",
      "input image max pixel: 0.3020, ground truth image max pixel: 0.2066, reconstructed image max pixel: 0.1554\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0013 - val_loss: 0.0013                      \n",
      "Epoch 25 completed in 564.38s - train_loss: 0.0013 - val_loss: 0.0013\n",
      "\n",
      "Epoch 26/100 - 61 batches\n",
      "input image max pixel: 0.1490, ground truth image max pixel: 0.0784, reconstructed image max pixel: 0.0894\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0013 - val_loss: 0.0013                      \n",
      "Epoch 26 completed in 574.59s - train_loss: 0.0013 - val_loss: 0.0013\n",
      "\n",
      "Epoch 27/100 - 61 batches\n",
      "input image max pixel: 0.2196, ground truth image max pixel: 0.1907, reconstructed image max pixel: 0.1618\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0012 - val_loss: 0.0011                      \n",
      "Epoch 27 completed in 554.12s - train_loss: 0.0012 - val_loss: 0.0011\n",
      "\n",
      "Epoch 28/100 - 61 batches\n",
      "input image max pixel: 0.2157, ground truth image max pixel: 0.4963, reconstructed image max pixel: 0.0858\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0012 - val_loss: 0.0012                      \n",
      "Epoch 28 completed in 543.85s - train_loss: 0.0012 - val_loss: 0.0012\n",
      "\n",
      "Epoch 29/100 - 61 batches\n",
      "input image max pixel: 0.0431, ground truth image max pixel: 0.0078, reconstructed image max pixel: 0.0847\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0011 - val_loss: 0.0010                      \n",
      "Epoch 29 completed in 542.15s - train_loss: 0.0011 - val_loss: 0.0010\n",
      "\n",
      "Epoch 30/100 - 61 batches\n",
      "input image max pixel: 0.0784, ground truth image max pixel: 0.0118, reconstructed image max pixel: 0.0830\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0011 - val_loss: 0.0012                      \n",
      "Epoch 30 completed in 563.03s - train_loss: 0.0011 - val_loss: 0.0012\n",
      "\n",
      "Epoch 31/100 - 61 batches\n",
      "input image max pixel: 0.1098, ground truth image max pixel: 0.2063, reconstructed image max pixel: 0.1315\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0011 - val_loss: 0.0009                      \n",
      "Epoch 31 completed in 569.93s - train_loss: 0.0011 - val_loss: 0.0009\n",
      "\n",
      "Epoch 32/100 - 61 batches\n",
      "input image max pixel: 0.0392, ground truth image max pixel: 0.0078, reconstructed image max pixel: 0.0793\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0010 - val_loss: 0.0011                      \n",
      "Epoch 32 completed in 565.33s - train_loss: 0.0010 - val_loss: 0.0011\n",
      "\n",
      "Epoch 33/100 - 61 batches\n",
      "input image max pixel: 0.0902, ground truth image max pixel: 0.0118, reconstructed image max pixel: 0.0778\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0010 - val_loss: 0.0008                      \n",
      "Epoch 33 completed in 561.70s - train_loss: 0.0010 - val_loss: 0.0008\n",
      "\n",
      "Epoch 34/100 - 61 batches\n",
      "input image max pixel: 0.3069, ground truth image max pixel: 0.3907, reconstructed image max pixel: 0.2377\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0010 - val_loss: 0.0013                      \n",
      "Epoch 34 completed in 561.21s - train_loss: 0.0010 - val_loss: 0.0013\n",
      "\n",
      "Epoch 35/100 - 61 batches\n",
      "input image max pixel: 0.4431, ground truth image max pixel: 0.1675, reconstructed image max pixel: 0.3350\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0009 - val_loss: 0.0011                      \n",
      "Epoch 35 completed in 565.43s - train_loss: 0.0009 - val_loss: 0.0011\n",
      "\n",
      "Epoch 36/100 - 61 batches\n",
      "input image max pixel: 0.3481, ground truth image max pixel: 0.1680, reconstructed image max pixel: 0.3811\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0009 - val_loss: 0.0011                      \n",
      "Epoch 36 completed in 565.86s - train_loss: 0.0009 - val_loss: 0.0011\n",
      "\n",
      "Epoch 37/100 - 61 batches\n",
      "input image max pixel: 0.1922, ground truth image max pixel: 0.0464, reconstructed image max pixel: 0.0707\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0009 - val_loss: 0.0009                      \n",
      "Epoch 37 completed in 559.64s - train_loss: 0.0009 - val_loss: 0.0009\n",
      "\n",
      "Epoch 38/100 - 61 batches\n",
      "input image max pixel: 0.3706, ground truth image max pixel: 0.1753, reconstructed image max pixel: 0.3473\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0008 - val_loss: 0.0008                      \n",
      "Epoch 38 completed in 559.47s - train_loss: 0.0008 - val_loss: 0.0008\n",
      "\n",
      "Epoch 39/100 - 61 batches\n",
      "input image max pixel: 0.1137, ground truth image max pixel: 0.0784, reconstructed image max pixel: 0.0702\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0008 - val_loss: 0.0008                      \n",
      "Epoch 39 completed in 548.26s - train_loss: 0.0008 - val_loss: 0.0008\n",
      "\n",
      "Epoch 40/100 - 61 batches\n",
      "input image max pixel: 0.0275, ground truth image max pixel: 0.0078, reconstructed image max pixel: 0.0702\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0008 - val_loss: 0.0008                      \n",
      "Epoch 40 completed in 560.56s - train_loss: 0.0008 - val_loss: 0.0008\n",
      "\n",
      "Epoch 41/100 - 61 batches\n",
      "input image max pixel: 0.4696, ground truth image max pixel: 0.6518, reconstructed image max pixel: 0.2925\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0008 - val_loss: 0.0008                      \n",
      "Epoch 41 completed in 548.97s - train_loss: 0.0008 - val_loss: 0.0008\n",
      "\n",
      "Epoch 42/100 - 61 batches\n",
      "input image max pixel: 0.0431, ground truth image max pixel: 0.0078, reconstructed image max pixel: 0.0681\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0008 - val_loss: 0.0008                      \n",
      "Epoch 42 completed in 550.75s - train_loss: 0.0008 - val_loss: 0.0008\n",
      "\n",
      "Epoch 43/100 - 61 batches\n",
      "input image max pixel: 0.5137, ground truth image max pixel: 0.3200, reconstructed image max pixel: 0.4962\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0007 - val_loss: 0.0009                      \n",
      "Epoch 43 completed in 552.90s - train_loss: 0.0007 - val_loss: 0.0009\n",
      "\n",
      "Epoch 44/100 - 61 batches\n",
      "input image max pixel: 0.3490, ground truth image max pixel: 0.6423, reconstructed image max pixel: 0.4892\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0007 - val_loss: 0.0007                      \n",
      "Epoch 44 completed in 550.37s - train_loss: 0.0007 - val_loss: 0.0007\n",
      "\n",
      "Epoch 45/100 - 61 batches\n",
      "input image max pixel: 0.1804, ground truth image max pixel: 0.3268, reconstructed image max pixel: 0.4626\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0007 - val_loss: 0.0008                      \n",
      "Epoch 45 completed in 549.67s - train_loss: 0.0007 - val_loss: 0.0008\n",
      "\n",
      "Epoch 46/100 - 61 batches\n",
      "input image max pixel: 0.2264, ground truth image max pixel: 0.1319, reconstructed image max pixel: 0.0687\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0007 - val_loss: 0.0008                      \n",
      "Epoch 46 completed in 549.49s - train_loss: 0.0007 - val_loss: 0.0008\n",
      "\n",
      "Epoch 47/100 - 61 batches\n",
      "input image max pixel: 0.0366, ground truth image max pixel: 0.0078, reconstructed image max pixel: 0.0649\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0007 - val_loss: 0.0007                      \n",
      "Epoch 47 completed in 564.54s - train_loss: 0.0007 - val_loss: 0.0007\n",
      "\n",
      "Epoch 48/100 - 61 batches\n",
      "input image max pixel: 0.3020, ground truth image max pixel: 0.2745, reconstructed image max pixel: 0.3010\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0007 - val_loss: 0.0006                      \n",
      "Epoch 48 completed in 554.24s - train_loss: 0.0007 - val_loss: 0.0006\n",
      "\n",
      "Epoch 49/100 - 61 batches\n",
      "input image max pixel: 0.1373, ground truth image max pixel: 0.5209, reconstructed image max pixel: 0.5102\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0006 - val_loss: 0.0008                      \n",
      "Epoch 49 completed in 552.68s - train_loss: 0.0006 - val_loss: 0.0008\n",
      "\n",
      "Epoch 50/100 - 61 batches\n",
      "input image max pixel: 0.0941, ground truth image max pixel: 0.2952, reconstructed image max pixel: 0.3777\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0006 - val_loss: 0.0007                      \n",
      "Epoch 50 completed in 3078.81s - train_loss: 0.0006 - val_loss: 0.0007\n",
      "\n",
      "Epoch 51/100 - 61 batches\n",
      "input image max pixel: 0.0902, ground truth image max pixel: 0.5829, reconstructed image max pixel: 0.4087\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0006 - val_loss: 0.0006                      \n",
      "Epoch 51 completed in 577.77s - train_loss: 0.0006 - val_loss: 0.0006\n",
      "\n",
      "Epoch 52/100 - 61 batches\n",
      "input image max pixel: 0.1176, ground truth image max pixel: 0.1867, reconstructed image max pixel: 0.1171\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0006 - val_loss: 0.0006                      \n",
      "Epoch 52 completed in 593.71s - train_loss: 0.0006 - val_loss: 0.0006\n",
      "\n",
      "Epoch 53/100 - 61 batches\n",
      "input image max pixel: 0.1255, ground truth image max pixel: 0.5622, reconstructed image max pixel: 0.4134\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0006 - val_loss: 0.0007                      \n",
      "Epoch 53 completed in 660.31s - train_loss: 0.0006 - val_loss: 0.0007\n",
      "\n",
      "Epoch 54/100 - 61 batches\n",
      "input image max pixel: 0.1373, ground truth image max pixel: 0.5922, reconstructed image max pixel: 0.2366\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0005 - val_loss: 0.0006                      \n",
      "Epoch 54 completed in 721.05s - train_loss: 0.0005 - val_loss: 0.0006\n",
      "\n",
      "Epoch 55/100 - 61 batches\n",
      "input image max pixel: 0.1207, ground truth image max pixel: 0.1384, reconstructed image max pixel: 0.0563\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0005 - val_loss: 0.0007                      \n",
      "Epoch 55 completed in 653.11s - train_loss: 0.0005 - val_loss: 0.0007\n",
      "\n",
      "Epoch 56/100 - 61 batches\n",
      "input image max pixel: 0.4588, ground truth image max pixel: 0.1981, reconstructed image max pixel: 0.2392\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0005 - val_loss: 0.0006                      \n",
      "Epoch 56 completed in 1292.54s - train_loss: 0.0005 - val_loss: 0.0006\n",
      "\n",
      "Epoch 57/100 - 61 batches\n",
      "input image max pixel: 0.1451, ground truth image max pixel: 0.6109, reconstructed image max pixel: 0.5620\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0005 - val_loss: 0.0006                      \n",
      "Epoch 57 completed in 625.91s - train_loss: 0.0005 - val_loss: 0.0006\n",
      "\n",
      "Epoch 58/100 - 61 batches\n",
      "input image max pixel: 0.1373, ground truth image max pixel: 0.0902, reconstructed image max pixel: 0.1403\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0005 - val_loss: 0.0005                      \n",
      "Epoch 58 completed in 624.51s - train_loss: 0.0005 - val_loss: 0.0005\n",
      "\n",
      "Epoch 59/100 - 61 batches\n",
      "input image max pixel: 0.0863, ground truth image max pixel: 0.4992, reconstructed image max pixel: 0.3507\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0005 - val_loss: 0.0006                      \n",
      "Epoch 59 completed in 616.98s - train_loss: 0.0005 - val_loss: 0.0006\n",
      "\n",
      "Epoch 60/100 - 61 batches\n",
      "input image max pixel: 0.4678, ground truth image max pixel: 0.3238, reconstructed image max pixel: 0.4737\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0005 - val_loss: 0.0006                      \n",
      "Epoch 60 completed in 613.86s - train_loss: 0.0005 - val_loss: 0.0006\n",
      "\n",
      "Epoch 61/100 - 61 batches\n",
      "input image max pixel: 0.0824, ground truth image max pixel: 0.1326, reconstructed image max pixel: 0.1819\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0005 - val_loss: 0.0005                      \n",
      "Epoch 61 completed in 619.78s - train_loss: 0.0005 - val_loss: 0.0005\n",
      "\n",
      "Epoch 62/100 - 61 batches\n",
      "input image max pixel: 0.3706, ground truth image max pixel: 0.3534, reconstructed image max pixel: 0.3872\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0005 - val_loss: 0.0006                      \n",
      "Epoch 62 completed in 633.26s - train_loss: 0.0005 - val_loss: 0.0006\n",
      "\n",
      "Epoch 63/100 - 61 batches\n",
      "input image max pixel: 0.4130, ground truth image max pixel: 0.1680, reconstructed image max pixel: 0.4094\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0005 - val_loss: 0.0006                      \n",
      "Epoch 63 completed in 626.62s - train_loss: 0.0005 - val_loss: 0.0006\n",
      "\n",
      "Epoch 64/100 - 61 batches\n",
      "input image max pixel: 0.4353, ground truth image max pixel: 0.2208, reconstructed image max pixel: 0.2954\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0005 - val_loss: 0.0005                      \n",
      "Epoch 64 completed in 634.69s - train_loss: 0.0005 - val_loss: 0.0005\n",
      "\n",
      "Epoch 65/100 - 61 batches\n",
      "input image max pixel: 0.5176, ground truth image max pixel: 0.6700, reconstructed image max pixel: 0.5374\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0005 - val_loss: 0.0006                      \n",
      "Epoch 65 completed in 624.16s - train_loss: 0.0005 - val_loss: 0.0006\n",
      "\n",
      "Epoch 66/100 - 61 batches\n",
      "input image max pixel: 0.0863, ground truth image max pixel: 0.0097, reconstructed image max pixel: 0.0525\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0004 - val_loss: 0.0007                      \n",
      "Epoch 66 completed in 618.96s - train_loss: 0.0004 - val_loss: 0.0007\n",
      "\n",
      "Epoch 67/100 - 61 batches\n",
      "input image max pixel: 0.3490, ground truth image max pixel: 0.4405, reconstructed image max pixel: 0.4206\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0004 - val_loss: 0.0005                      \n",
      "Epoch 67 completed in 631.21s - train_loss: 0.0004 - val_loss: 0.0005\n",
      "\n",
      "Epoch 68/100 - 61 batches\n",
      "input image max pixel: 0.3266, ground truth image max pixel: 0.1176, reconstructed image max pixel: 0.1280\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0004 - val_loss: 0.0005                      \n",
      "Epoch 68 completed in 625.65s - train_loss: 0.0004 - val_loss: 0.0005\n",
      "\n",
      "Epoch 69/100 - 61 batches\n",
      "input image max pixel: 0.1137, ground truth image max pixel: 0.0784, reconstructed image max pixel: 0.0488\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0004 - val_loss: 0.0005                      \n",
      "Epoch 69 completed in 622.64s - train_loss: 0.0004 - val_loss: 0.0005\n",
      "\n",
      "Epoch 70/100 - 61 batches\n",
      "input image max pixel: 0.3412, ground truth image max pixel: 0.1333, reconstructed image max pixel: 0.1999\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0004 - val_loss: 0.0006                      \n",
      "Epoch 70 completed in 622.44s - train_loss: 0.0004 - val_loss: 0.0006\n",
      "\n",
      "Epoch 71/100 - 61 batches\n",
      "input image max pixel: 0.4157, ground truth image max pixel: 0.8731, reconstructed image max pixel: 0.6682\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0004 - val_loss: 0.0005                      \n",
      "Epoch 71 completed in 622.80s - train_loss: 0.0004 - val_loss: 0.0005\n",
      "\n",
      "Epoch 72/100 - 61 batches\n",
      "input image max pixel: 0.0980, ground truth image max pixel: 0.6249, reconstructed image max pixel: 0.2040\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0004 - val_loss: 0.0006                      \n",
      "Epoch 72 completed in 622.92s - train_loss: 0.0004 - val_loss: 0.0006\n",
      "\n",
      "Epoch 73/100 - 61 batches\n",
      "input image max pixel: 0.3490, ground truth image max pixel: 0.6423, reconstructed image max pixel: 0.6416\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0004 - val_loss: 0.0005                      \n",
      "Epoch 73 completed in 583.78s - train_loss: 0.0004 - val_loss: 0.0005\n",
      "\n",
      "Epoch 74/100 - 61 batches\n",
      "input image max pixel: 0.0902, ground truth image max pixel: 0.0314, reconstructed image max pixel: 0.2219\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0004 - val_loss: 0.0006                      \n",
      "Epoch 74 completed in 564.52s - train_loss: 0.0004 - val_loss: 0.0006\n",
      "\n",
      "Epoch 75/100 - 61 batches\n",
      "input image max pixel: 0.4353, ground truth image max pixel: 0.8061, reconstructed image max pixel: 0.6186\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0004 - val_loss: 0.0005                      \n",
      "Epoch 75 completed in 550.24s - train_loss: 0.0004 - val_loss: 0.0005\n",
      "\n",
      "Epoch 76/100 - 61 batches\n",
      "input image max pixel: 0.5020, ground truth image max pixel: 0.2496, reconstructed image max pixel: 0.2928\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0004 - val_loss: 0.0005                      \n",
      "Epoch 76 completed in 554.57s - train_loss: 0.0004 - val_loss: 0.0005\n",
      "\n",
      "Epoch 77/100 - 61 batches\n",
      "input image max pixel: 0.4353, ground truth image max pixel: 0.5585, reconstructed image max pixel: 0.5247\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0004 - val_loss: 0.0006                      \n",
      "Epoch 77 completed in 548.34s - train_loss: 0.0004 - val_loss: 0.0006\n",
      "\n",
      "Epoch 78/100 - 61 batches\n",
      "input image max pixel: 0.2000, ground truth image max pixel: 0.2300, reconstructed image max pixel: 0.3650\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0004 - val_loss: 0.0005                      \n",
      "Epoch 78 completed in 547.92s - train_loss: 0.0004 - val_loss: 0.0005\n",
      "\n",
      "Epoch 79/100 - 61 batches\n",
      "input image max pixel: 0.1843, ground truth image max pixel: 0.4066, reconstructed image max pixel: 0.2899\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0004 - val_loss: 0.0005                      \n",
      "Epoch 79 completed in 547.93s - train_loss: 0.0004 - val_loss: 0.0005\n",
      "\n",
      "Epoch 80/100 - 61 batches\n",
      "input image max pixel: 0.1451, ground truth image max pixel: 0.6109, reconstructed image max pixel: 0.4906\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0004 - val_loss: 0.0004                      \n",
      "Epoch 80 completed in 547.59s - train_loss: 0.0004 - val_loss: 0.0004\n",
      "\n",
      "Epoch 81/100 - 61 batches\n",
      "input image max pixel: 0.0824, ground truth image max pixel: 0.0390, reconstructed image max pixel: 0.0686\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0003 - val_loss: 0.0004                      \n",
      "Epoch 81 completed in 551.04s - train_loss: 0.0003 - val_loss: 0.0004\n",
      "\n",
      "Epoch 82/100 - 61 batches\n",
      "input image max pixel: 0.2275, ground truth image max pixel: 0.2274, reconstructed image max pixel: 0.1018\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0003 - val_loss: 0.0005                      \n",
      "Epoch 82 completed in 548.32s - train_loss: 0.0003 - val_loss: 0.0005\n",
      "\n",
      "Epoch 83/100 - 61 batches\n",
      "input image max pixel: 0.3020, ground truth image max pixel: 0.5982, reconstructed image max pixel: 0.5288\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0003 - val_loss: 0.0003                      \n",
      "Epoch 83 completed in 547.62s - train_loss: 0.0003 - val_loss: 0.0003\n",
      "\n",
      "Epoch 84/100 - 61 batches\n",
      "input image max pixel: 0.1412, ground truth image max pixel: 0.0157, reconstructed image max pixel: 0.0427\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0003 - val_loss: 0.0004                      \n",
      "Epoch 84 completed in 548.25s - train_loss: 0.0003 - val_loss: 0.0004\n",
      "\n",
      "Epoch 85/100 - 61 batches\n",
      "input image max pixel: 0.2235, ground truth image max pixel: 0.7283, reconstructed image max pixel: 0.6582\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0003 - val_loss: 0.0004                      \n",
      "Epoch 85 completed in 545.56s - train_loss: 0.0003 - val_loss: 0.0004\n",
      "\n",
      "Epoch 86/100 - 61 batches\n",
      "input image max pixel: 0.0863, ground truth image max pixel: 0.0275, reconstructed image max pixel: 0.1631\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0003 - val_loss: 0.0004                      \n",
      "Epoch 86 completed in 546.63s - train_loss: 0.0003 - val_loss: 0.0004\n",
      "\n",
      "Epoch 87/100 - 61 batches\n",
      "input image max pixel: 0.1373, ground truth image max pixel: 0.0902, reconstructed image max pixel: 0.1580\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0003 - val_loss: 0.0004                      \n",
      "Epoch 87 completed in 546.60s - train_loss: 0.0003 - val_loss: 0.0004\n",
      "\n",
      "Epoch 88/100 - 61 batches\n",
      "input image max pixel: 0.0980, ground truth image max pixel: 0.1205, reconstructed image max pixel: 0.1567\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0003 - val_loss: 0.0004                      \n",
      "Epoch 88 completed in 547.09s - train_loss: 0.0003 - val_loss: 0.0004\n",
      "\n",
      "Epoch 89/100 - 61 batches\n",
      "input image max pixel: 0.4863, ground truth image max pixel: 0.6142, reconstructed image max pixel: 0.5195\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0003 - val_loss: 0.0004                      \n",
      "Epoch 89 completed in 546.46s - train_loss: 0.0003 - val_loss: 0.0004\n",
      "\n",
      "Epoch 90/100 - 61 batches\n",
      "input image max pixel: 0.2600, ground truth image max pixel: 0.2471, reconstructed image max pixel: 0.4003\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0003 - val_loss: 0.0005                      \n",
      "Epoch 90 completed in 545.90s - train_loss: 0.0003 - val_loss: 0.0005\n",
      "\n",
      "Epoch 91/100 - 61 batches\n",
      "input image max pixel: 0.0784, ground truth image max pixel: 0.4544, reconstructed image max pixel: 0.3433\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0003 - val_loss: 0.0004                      \n",
      "Epoch 91 completed in 545.45s - train_loss: 0.0003 - val_loss: 0.0004\n",
      "\n",
      "Epoch 92/100 - 61 batches\n",
      "input image max pixel: 0.2157, ground truth image max pixel: 0.2341, reconstructed image max pixel: 0.3429\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0003 - val_loss: 0.0003                      \n",
      "Epoch 92 completed in 546.31s - train_loss: 0.0003 - val_loss: 0.0003\n",
      "\n",
      "Epoch 93/100 - 61 batches\n",
      "input image max pixel: 0.3725, ground truth image max pixel: 0.1411, reconstructed image max pixel: 0.1364\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0003 - val_loss: 0.0003                      \n",
      "Epoch 93 completed in 546.80s - train_loss: 0.0003 - val_loss: 0.0003\n",
      "\n",
      "Epoch 94/100 - 61 batches\n",
      "input image max pixel: 0.0824, ground truth image max pixel: 0.0390, reconstructed image max pixel: 0.0542\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0003 - val_loss: 0.0004                      \n",
      "Epoch 94 completed in 545.70s - train_loss: 0.0003 - val_loss: 0.0004\n",
      "\n",
      "Epoch 95/100 - 61 batches\n",
      "input image max pixel: 0.3686, ground truth image max pixel: 0.7587, reconstructed image max pixel: 0.6612\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0003 - val_loss: 0.0004                      \n",
      "Epoch 95 completed in 546.93s - train_loss: 0.0003 - val_loss: 0.0004\n",
      "\n",
      "Epoch 96/100 - 61 batches\n",
      "input image max pixel: 0.1412, ground truth image max pixel: 0.5922, reconstructed image max pixel: 0.7077\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0003 - val_loss: 0.0004                      \n",
      "Epoch 96 completed in 545.83s - train_loss: 0.0003 - val_loss: 0.0004\n",
      "\n",
      "Epoch 97/100 - 61 batches\n",
      "input image max pixel: 0.3333, ground truth image max pixel: 0.3360, reconstructed image max pixel: 0.4352\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0003 - val_loss: 0.0005                      \n",
      "Epoch 97 completed in 547.53s - train_loss: 0.0003 - val_loss: 0.0005\n",
      "\n",
      "Epoch 98/100 - 61 batches\n",
      "input image max pixel: 0.3725, ground truth image max pixel: 0.2850, reconstructed image max pixel: 0.3986\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0003 - val_loss: 0.0004                      \n",
      "Epoch 98 completed in 544.71s - train_loss: 0.0003 - val_loss: 0.0004\n",
      "\n",
      "Epoch 99/100 - 61 batches\n",
      "input image max pixel: 0.0863, ground truth image max pixel: 0.0667, reconstructed image max pixel: 0.1414\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0003 - val_loss: 0.0004                      \n",
      "Epoch 99 completed in 547.41s - train_loss: 0.0003 - val_loss: 0.0004\n",
      "\n",
      "Epoch 100/100 - 61 batches\n",
      "input image max pixel: 0.3706, ground truth image max pixel: 0.1753, reconstructed image max pixel: 0.3694\n",
      "[==============================] 61/61 (100.0%) - ETA: 0s - train_loss: 0.0002 - val_loss: 0.0003                      \n",
      "Epoch 100 completed in 547.97s - train_loss: 0.0002 - val_loss: 0.0003\n",
      "\n",
      "Training completed!\n",
      "Restored best weights with val_loss=0.0003\n",
      "Training ALL complete.\n"
     ]
    }
   ],
   "source": [
    "# ==================== \n",
    "# Training\n",
    "# ====================\n",
    "from functools import partial\n",
    "import torch.nn as nn\n",
    "\n",
    "from xflow import TorchTrainer, TorchGANTrainer\n",
    "from xflow.trainers import build_callbacks_from_config\n",
    "from xflow.extensions.physics.beam import extract_beam_parameters\n",
    "\n",
    "# 1) loss/optimizer\n",
    "# criterion = torch.nn.MSELoss()\n",
    "\n",
    "# loss function with weighting on high-intensity regions\n",
    "class WeightedMSELoss(nn.Module):\n",
    "    def __init__(self, alpha=5.0, beta=0.5):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "    def forward(self, pred, gt):\n",
    "        weight = 1.0 + self.alpha * (gt.clamp(min=0.) ** self.beta)\n",
    "        return (weight * (pred - gt) ** 2).mean()\n",
    "\n",
    "criterion = WeightedMSELoss(alpha=5.0, beta=0.5)\n",
    "\n",
    "# 2) callbacks (unchanged) + any custom wiring\n",
    "callbacks = build_callbacks_from_config(\n",
    "    config=config[\"callbacks\"],\n",
    "    framework=config[\"framework\"],  \n",
    ") # keep dataset closure for last callback, sequence hardcoded\n",
    "callbacks[-1].set_dataset(test_dataset)\n",
    "\n",
    "# Extract beam parameters closure (return as dict)\n",
    "if model_name in SAMPLE_FLATTENED:\n",
    "    extract_beam_parameters_dict = partial(extract_beam_parameters_flat, as_array=False)\n",
    "    beam_param_metric = make_beam_param_metric(extract_beam_parameters_dict)\n",
    "elif model_name in REGRESSION:   # e.g., \"ERN\"\n",
    "    beam_param_metric = make_param_metric()\n",
    "else:\n",
    "    extract_beam_parameters_dict = partial(extract_beam_parameters, as_array=False)\n",
    "    beam_param_metric = make_beam_param_metric(extract_beam_parameters_dict)\n",
    "\n",
    "# 3) run training\n",
    "if model_name in GAN:\n",
    "    trainer = TorchGANTrainer(\n",
    "        generator=G,\n",
    "        discriminator=D,\n",
    "        optimizer_g=opt_g,\n",
    "        optimizer_d=opt_d,\n",
    "        losses=losses,\n",
    "        device=device,\n",
    "        callbacks=callbacks,\n",
    "        output_dir=config[\"paths\"][\"output\"],\n",
    "        data_pipeline=train_dataset,\n",
    "        val_metrics=[beam_param_metric],\n",
    "    )\n",
    "else:\n",
    "    trainer = TorchTrainer(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        device=device,\n",
    "        callbacks=callbacks,\n",
    "        output_dir=config[\"paths\"][\"output\"],\n",
    "        data_pipeline=train_dataset,\n",
    "        val_metrics=[beam_param_metric],\n",
    "        scheduler= scheduler if model_name == \"SwinT\" else None, \n",
    "        scheduler_step_per_batch=True,\n",
    "    )\n",
    "\n",
    "history = trainer.fit(\n",
    "    train_loader=train_dataset, \n",
    "    val_loader=val_dataset,\n",
    "    epochs=config['training']['epochs'],\n",
    ")\n",
    "\n",
    "# 4) save results\n",
    "trainer.save_history(f\"{config['paths']['output']}/history.json\")\n",
    "trainer.save_model(config[\"paths\"][\"output\"])  # uses model.save_model(...) if available\n",
    "config_manager.save(output_dir=config[\"paths\"][\"output\"], config_filename=config[\"name\"])\n",
    "\n",
    "print(\"Training ALL complete.\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ed03c6",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10fec9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to /Users/andrewxu/Desktop/untitled folder 2\n"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "save_dir = Path(\"/Users/andrewxu/Desktop/untitled folder 2\")\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device).eval()\n",
    "\n",
    "def _save_triplet(idx, inp_tensor, gt_tensor, pred_tensor):\n",
    "    torch.save(\n",
    "        {\"input\": inp_tensor, \"ground_truth\": gt_tensor, \"prediction\": pred_tensor},\n",
    "        save_dir / f\"sample_{idx:05d}.pt\",\n",
    "    )\n",
    "    save_image(inp_tensor[0], str(save_dir / f\"input_{idx:05d}.png\"))\n",
    "    save_image(gt_tensor[0], str(save_dir / f\"ground_truth_{idx:05d}.png\"))\n",
    "    save_image(pred_tensor[0], str(save_dir / f\"prediction_{idx:05d}.png\"))\n",
    "\n",
    "with torch.no_grad():\n",
    "    if model_name in REGRESSION:\n",
    "        for idx, (left_parts, params, right_parts) in enumerate(test_dataset):\n",
    "            inputs = left_parts.to(device)\n",
    "            targets = right_parts.to(device)\n",
    "            params = params.to(device) if torch.is_tensor(params) else params\n",
    "            preds = model(inputs, params).cpu()\n",
    "\n",
    "            _save_triplet(idx, inputs.cpu(), targets.cpu(), preds)\n",
    "    else:\n",
    "        for idx, (left_parts, right_parts) in enumerate(test_dataset):\n",
    "            inputs = left_parts.to(device)\n",
    "            targets = right_parts.to(device)\n",
    "            preds = model(inputs).cpu()\n",
    "\n",
    "            if model_name in SAMPLE_FLATTENED:\n",
    "                inp = inputs.cpu()\n",
    "                tgt = targets.cpu()\n",
    "                pred = preds\n",
    "                inp[0] = inp[0].reshape(*config[\"data\"][\"input_shape\"])\n",
    "                tgt[0] = tgt[0].reshape(*config[\"data\"][\"output_shape\"])\n",
    "                pred[0] = pred[0].reshape(*config[\"data\"][\"output_shape\"])\n",
    "                _save_triplet(idx, inp, tgt, pred)\n",
    "            else:\n",
    "                _save_triplet(idx, inputs.cpu(), targets.cpu(), preds)\n",
    "\n",
    "print(f\"Saved predictions to {save_dir}\")\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed79f052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
