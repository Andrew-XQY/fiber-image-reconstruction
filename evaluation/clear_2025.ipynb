{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79336363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/andrewxu/Documents/GitHub/fiber-image-reconstruction\n",
      "[config_utils] Using machine profile: mac-andrewxu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "os.chdir(Path.cwd().parent)   # go one level up\n",
    "print(os.getcwd())            # check\n",
    "\n",
    "# pip install xflow-py\n",
    "from xflow import ConfigManager, SqlProvider, PyTorchPipeline, show_model_info\n",
    "from xflow.data import build_transforms_from_config\n",
    "from xflow.utils import load_validated_config, save_image\n",
    "import xflow.extensions.physics\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import tarfile\n",
    "from datetime import datetime  \n",
    "from config_utils import load_config\n",
    "from utils import *\n",
    "\n",
    "\n",
    "# Create experiment output directory  (timestamped)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")  \n",
    "\n",
    "experiment_name = \"CAE\"  # TM, SHL_DNN, U_Net, Pix2pix, ERN, CAE, SwinT, CAE_syth\n",
    "folder_name = f\"{experiment_name}-{timestamp}\"  \n",
    "config_manager = ConfigManager(load_config(f\"{experiment_name}.yaml\", \n",
    "                                           experiment_name=folder_name))\n",
    "config = config_manager.get()\n",
    "config_manager.add_files(config[\"extra_files\"])\n",
    "\n",
    "experiment_output_dir = config[\"paths\"][\"output\"]\n",
    "os.makedirs(experiment_output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# New structure, read the database table first, get files from it.\n",
    "# Extract tar file if needed\n",
    "if config['file_extract']:\n",
    "    dataset_tar_file = os.path.join(config[\"paths\"][\"dataset\"], config[\"data\"][\"dataset\"])\n",
    "    dataset_base_dir = os.path.dirname(dataset_tar_file)\n",
    "    dataset_name = os.path.splitext(config[\"data\"][\"dataset\"])[0]  # Remove .tar extension\n",
    "    dataset_extracted_dir = os.path.join(dataset_base_dir, dataset_name)\n",
    "\n",
    "    # Unzip tar file if not already extracted\n",
    "    if not os.path.exists(dataset_extracted_dir):\n",
    "        print(f\"Extracting {dataset_tar_file}...\")\n",
    "        with tarfile.open(dataset_tar_file, 'r') as tar:\n",
    "            tar.extractall(path=dataset_base_dir)\n",
    "        print(f\"Extracted to {dataset_extracted_dir}\")\n",
    "    else:\n",
    "        print(f\"Dataset already extracted at {dataset_extracted_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3434c04d",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "093f1261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples:  4776 1627 1628\n",
      "Batch:  1194 407 407\n",
      "Batch shapes: torch.Size([4, 1, 256, 256]), torch.Size([4, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# ==================== \n",
    "# Prepare Dataset\n",
    "# ====================\n",
    "\n",
    "def make_dataset(provider):\n",
    "    return PyTorchPipeline(provider, transforms).to_memory_dataset(config[\"data\"][\"dataset_ops\"])\n",
    "\n",
    "train_dir = config[\"paths\"][\"training_set\"]\n",
    "# Create SqlProvider to query the database\n",
    "db_path = f\"{train_dir}/db/dataset_meta.db\"\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    image_path\n",
    "FROM mmf_dataset_metadata \n",
    "WHERE batch IN (15)\n",
    "--LIMIT 20\n",
    "\"\"\"\n",
    "train_provider = SqlProvider(\n",
    "    sources={\"connection\": db_path, \"sql\": query}, output_config={'list': \"image_path\"}\n",
    ")\n",
    "\n",
    "test_dir = config[\"paths\"][\"test_set\"]\n",
    "# Create SqlProvider to query the database\n",
    "db_path = f\"{test_dir}/db/dataset_meta.db\"\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    image_path\n",
    "FROM mmf_dataset_metadata \n",
    "WHERE batch IN (1)\n",
    "--LIMIT 20\n",
    "\"\"\"\n",
    "evaluation_provider = SqlProvider(\n",
    "    sources={\"connection\": db_path, \"sql\": query}, output_config={'list': \"image_path\"}\n",
    ")\n",
    "val_provider, test_provider = evaluation_provider.split(ratio=config[\"data\"][\"val_test_split\"], seed=config[\"seed\"])\n",
    "\n",
    "\n",
    "# For train dataset\n",
    "config[\"data\"][\"transforms\"][\"torch\"].insert(0, {\n",
    "    \"name\": \"add_parent_dir\",\n",
    "    \"params\": {\n",
    "        \"parent_dir\": train_dir\n",
    "    }\n",
    "})\n",
    "transforms = build_transforms_from_config(config[\"data\"][\"transforms\"][\"torch\"])\n",
    "train_dataset = make_dataset(train_provider)\n",
    "\n",
    "# For test datasets\n",
    "config[\"data\"][\"transforms\"][\"torch\"][0][\"params\"][\"parent_dir\"] = test_dir\n",
    "transforms = build_transforms_from_config(config[\"data\"][\"transforms\"][\"torch\"])\n",
    "val_dataset = make_dataset(val_provider)\n",
    "test_dataset = make_dataset(test_provider)\n",
    "\n",
    "print(\"Samples: \",len(train_provider),len(val_provider),len(test_provider))\n",
    "print(\"Batch: \",len(train_dataset),len(val_dataset),len(test_dataset))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# save a sample from dataset for debugging\n",
    "if experiment_name in REGRESSION:\n",
    "    for left_parts, params, right_parts in test_dataset:\n",
    "        print(f\"Batch shapes: {left_parts.shape}, {right_parts.shape}\")\n",
    "        save_image(left_parts[0], config[\"paths\"][\"output\"] + \"/input.png\")\n",
    "        save_image(right_parts[0], config[\"paths\"][\"output\"] + \"/output.png\")\n",
    "        break\n",
    "else:\n",
    "    for index, sample in enumerate(test_dataset):  # test_dataset\n",
    "        left_parts, right_parts = sample\n",
    "        # batch will be a tuple: (right_halves, left_halves) due to split_width\n",
    "        print(f\"Batch shapes: {left_parts.shape}, {right_parts.shape}\")\n",
    "        if experiment_name in SAMPLE_FLATTENED:\n",
    "            save_image(left_parts[0].reshape(config['data']['input_shape']), config[\"paths\"][\"output\"] + f\"/input_{index}.png\")\n",
    "            save_image(right_parts[0].reshape(config['data']['output_shape']), config[\"paths\"][\"output\"] + f\"/output_{index}.png\")\n",
    "        else:\n",
    "            save_image(left_parts[0], config[\"paths\"][\"output\"] + f\"/input_{index}.png\")\n",
    "            save_image(right_parts[0], config[\"paths\"][\"output\"] + f\"/output_{index}.png\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f436c74c",
   "metadata": {},
   "source": [
    "# Construct Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c745409a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected framework: PyTorch\n",
      "Framework:           PyTorch\n",
      "Model:               Autoencoder2D\n",
      "Device / dtype:      unavailable / N/A\n",
      "Parameters:          18,620,544 total\n",
      "                     18,620,544 trainable\n",
      "                     0 non-trainable\n",
      "Size:                71.06 MB\n",
      "Sub-modules:         67\n"
     ]
    }
   ],
   "source": [
    "# ==================== \n",
    "# Construct Model\n",
    "# ====================\n",
    "if experiment_name == \"CAE\":\n",
    "    from models.CAE import Autoencoder2D\n",
    "    model = Autoencoder2D(\n",
    "        in_channels=int(config['model'][\"in_channels\"]),\n",
    "        encoder=config['model'][\"encoder\"],\n",
    "        decoder=config['model'][\"decoder\"],\n",
    "        kernel_size=int(config['model'][\"kernel_size\"]),\n",
    "        apply_batchnorm=config['model'][\"apply_batchnorm\"],\n",
    "        apply_dropout=config['model'][\"apply_dropout\"],\n",
    "        final_activation=str(config['model'][\"final_activation\"]),\n",
    "    )\n",
    "elif experiment_name == \"TM\":\n",
    "    from models.TM import TransmissionMatrix\n",
    "    model = TransmissionMatrix(\n",
    "        input_height = config[\"data\"][\"input_shape\"][0],\n",
    "        input_width = config[\"data\"][\"input_shape\"][1],\n",
    "        output_height = config[\"data\"][\"output_shape\"][0],\n",
    "        output_width = config[\"data\"][\"output_shape\"][1],\n",
    "        initialization = \"xavier\",\n",
    "    )\n",
    "elif experiment_name == \"SHL_DNN\":\n",
    "    from models.SHL_DNN import SHLNeuralNetwork\n",
    "    model = SHLNeuralNetwork(\n",
    "        input_size=config['data']['input_shape'][0] * config['data']['input_shape'][1],\n",
    "        hidden_size=config['model']['hidden_size'], \n",
    "        output_size=config['data']['output_shape'][0] * config['data']['output_shape'][1],\n",
    "        dropout_rate=config['model']['dropout_rate'],\n",
    "    )\n",
    "elif experiment_name == \"U_Net\":\n",
    "    from models.U_Net import UNet\n",
    "    model = UNet(\n",
    "        in_channels=config[\"model\"][\"in_channels\"],\n",
    "        encoder=config[\"model\"][\"encoder\"],\n",
    "        decoder=config[\"model\"][\"decoder\"],\n",
    "        kernel_size=config[\"model\"][\"kernel_size\"],\n",
    "        apply_batchnorm=config[\"model\"][\"apply_batchnorm\"],\n",
    "        apply_dropout=config[\"model\"][\"apply_dropout\"],\n",
    "        out_channels=config[\"model\"][\"out_channels\"],\n",
    "        final_activation=config[\"model\"][\"final_activation\"],\n",
    "    )\n",
    "elif experiment_name == \"SwinT\":\n",
    "    from models.SwinT import SwinUNet, ReconLoss\n",
    "    model = SwinUNet(\n",
    "        img_size=config['model']['img_size'],\n",
    "        in_chans=config['model']['in_chans'],\n",
    "        out_chans=config['model']['out_chans'],\n",
    "        embed_dim=config['model']['embed_dim'],\n",
    "        depths=config['model']['depths'],\n",
    "        num_heads=config['model']['num_heads'],\n",
    "        window_size=config['model']['window_size'],\n",
    "        patch_size=config['model']['patch_size'],\n",
    "    )\n",
    "elif experiment_name == \"Pix2pix\":\n",
    "    from models.Pix2pix import Generator, Discriminator, Pix2PixLosses\n",
    "    G = Generator(channels=config[\"model\"][\"channels\"])\n",
    "    D = Discriminator(channels=config[\"model\"][\"channels\"])\n",
    "    losses = Pix2PixLosses(lambda_l1=config[\"model\"][\"lambda_l1\"])\n",
    "    opt_g = torch.optim.Adam(G.parameters(), lr=config[\"training\"][\"learning_rate\"], betas=config[\"training\"][\"betas\"])\n",
    "    opt_d = torch.optim.Adam(D.parameters(), lr=config[\"training\"][\"learning_rate\"], betas=config[\"training\"][\"betas\"])\n",
    "elif experiment_name == \"ERN\":\n",
    "    from models.ERN import EncoderRegressor\n",
    "    model = EncoderRegressor(\n",
    "            in_channels=config['model']['in_channels'],\n",
    "            kernel_size=config['model']['kernel_size'],\n",
    "            encoder=config['model']['encoder'],\n",
    "            decoder=config['model']['decoder'],\n",
    "            final_activation=config['model']['final_activation'],  \n",
    "        )\n",
    "elif experiment_name == \"CAE_syth\":\n",
    "    from models.CAE import Autoencoder2D\n",
    "    model = Autoencoder2D(\n",
    "        in_channels=int(config['model'][\"in_channels\"]),\n",
    "        encoder=config['model'][\"encoder\"],\n",
    "        decoder=config['model'][\"decoder\"],\n",
    "        kernel_size=int(config['model'][\"kernel_size\"]),\n",
    "        apply_batchnorm=config['model'][\"apply_batchnorm\"],\n",
    "        apply_dropout=config['model'][\"apply_dropout\"],\n",
    "        final_activation=str(config['model'][\"final_activation\"]),\n",
    "    )\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "if experiment_name == \"Pix2pix\":\n",
    "    G = G.to(device)\n",
    "    D = D.to(device)\n",
    "    show_model_info(G)\n",
    "    show_model_info(D)\n",
    "elif experiment_name == \"SwinT\":\n",
    "    from torch.optim.lr_scheduler import LambdaLR\n",
    "    total_steps = config['training']['epochs'] * len(train_dataset)\n",
    "    warmup_steps = int(config['training']['warmup_ratio'] * total_steps)\n",
    "    def lr_lambda(step):\n",
    "        if step < warmup_steps:\n",
    "            return (step + 1) / max(1, warmup_steps)\n",
    "        t = (step - warmup_steps) / max(1, total_steps - warmup_steps)\n",
    "        return 0.5 * (1.0 + math.cos(math.pi * t))\n",
    "\n",
    "    model = model.to(device)\n",
    "    criterion = ReconLoss(w_l1=config['training']['w_l1'], w_ssim=config['training']['w_ssim']) # Loss: L1 + 0.3*SSIM\n",
    "\n",
    "    # Optimizer: AdamW with recommended params\n",
    "    base_lr = 4e-4 if config['training']['batch_size'] >= 64 else 2e-4\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=base_lr, betas=config['training']['betas'],\n",
    "        eps=config['training']['eps'], weight_decay=config['training']['weight_decay']\n",
    "    )\n",
    "    scheduler = LambdaLR(optimizer, lr_lambda)\n",
    "    show_model_info(model)\n",
    "else:\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['training']['learning_rate'])\n",
    "    show_model_info(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "248a65cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "Total epochs: 100\n",
      "\n",
      "Epoch 1/100 - 1194 batches\n",
      "input image max pixel: 0.0661, ground truth image max pixel: 0.1000, reconstructed image max pixel: 0.5000\n",
      "[==============================] 1194/1194 (100.0%) - ETA: 0s - train_loss: 0.0075 - val_loss: 0.0002                  \n",
      "Epoch 1 completed in 3068.26s - train_loss: 0.0075 - val_loss: 0.0002\n",
      "\n",
      "Epoch 2/100 - 1194 batches\n",
      "input image max pixel: 0.0669, ground truth image max pixel: 0.5813, reconstructed image max pixel: 0.1213\n",
      "[==============================] 1194/1194 (100.0%) - ETA: 0s - train_loss: 0.0006 - val_loss: 0.0001                  \n",
      "Epoch 2 completed in 3033.13s - train_loss: 0.0006 - val_loss: 0.0001\n",
      "\n",
      "Epoch 3/100 - 1194 batches\n",
      "input image max pixel: 0.0572, ground truth image max pixel: 0.1044, reconstructed image max pixel: 0.0787\n",
      "[==============================] 1194/1194 (100.0%) - ETA: 0s - train_loss: 0.0005 - val_loss: 0.0001                  \n",
      "Epoch 3 completed in 3020.84s - train_loss: 0.0005 - val_loss: 0.0001\n",
      "\n",
      "Epoch 4/100 - 1194 batches\n",
      "input image max pixel: 0.0598, ground truth image max pixel: 0.4624, reconstructed image max pixel: 0.0605\n",
      "[==============================] 1194/1194 (100.0%) - ETA: 0s - train_loss: 0.0005 - val_loss: 0.0001                  \n",
      "Epoch 4 completed in 3038.42s - train_loss: 0.0005 - val_loss: 0.0001\n",
      "\n",
      "Epoch 5/100 - 1194 batches\n",
      "input image max pixel: 0.0589, ground truth image max pixel: 0.3565, reconstructed image max pixel: 0.0530\n",
      "[==============================] 1194/1194 (100.0%) - ETA: 0s - train_loss: 0.0005 - val_loss: 0.0001                  \n",
      "Epoch 5 completed in 3005.91s - train_loss: 0.0005 - val_loss: 0.0001\n",
      "\n",
      "Epoch 6/100 - 1194 batches\n",
      "input image max pixel: 0.0571, ground truth image max pixel: 0.2584, reconstructed image max pixel: 0.0455\n",
      "[==============================] 1194/1194 (100.0%) - ETA: 0s - train_loss: 0.0004 - val_loss: 0.0001                  \n",
      "Epoch 6 completed in 2985.79s - train_loss: 0.0004 - val_loss: 0.0001\n",
      "\n",
      "Epoch 7/100 - 1194 batches\n",
      "input image max pixel: 0.0585, ground truth image max pixel: 0.1413, reconstructed image max pixel: 0.0410\n",
      "[==============================] 1194/1194 (100.0%) - ETA: 0s - train_loss: 0.0004 - val_loss: 0.0001                  \n",
      "Epoch 7 completed in 2982.07s - train_loss: 0.0004 - val_loss: 0.0001\n",
      "\n",
      "Epoch 8/100 - 1194 batches\n",
      "input image max pixel: 0.0568, ground truth image max pixel: 0.2160, reconstructed image max pixel: 0.0318\n",
      "[==============================] 1194/1194 (100.0%) - ETA: 0s - train_loss: 0.0004 - val_loss: 0.0001                  \n",
      "Epoch 8 completed in 2962.09s - train_loss: 0.0004 - val_loss: 0.0001\n",
      "\n",
      "Epoch 9/100 - 1194 batches\n",
      "input image max pixel: 0.0587, ground truth image max pixel: 0.5111, reconstructed image max pixel: 0.0959\n",
      "[==============================] 1194/1194 (100.0%) - ETA: 0s - train_loss: 0.0003 - val_loss: 0.0001                  \n",
      "Epoch 9 completed in 2970.05s - train_loss: 0.0003 - val_loss: 0.0001\n",
      "\n",
      "Epoch 10/100 - 1194 batches\n",
      "input image max pixel: 0.0608, ground truth image max pixel: 0.3015, reconstructed image max pixel: 0.0278\n",
      "[==============================] 1194/1194 (100.0%) - ETA: 0s - train_loss: 0.0003 - val_loss: 0.0001                  \n",
      "Epoch 10 completed in 2966.01s - train_loss: 0.0003 - val_loss: 0.0001\n",
      "\n",
      "Epoch 11/100 - 1194 batches\n",
      "input image max pixel: 0.0580, ground truth image max pixel: 0.3420, reconstructed image max pixel: 0.0246\n",
      "[==============================] 1194/1194 (100.0%) - ETA: 0s - train_loss: 0.0003 - val_loss: 0.0001                  \n",
      "Epoch 11 completed in 2979.95s - train_loss: 0.0003 - val_loss: 0.0001\n",
      "\n",
      "Epoch 12/100 - 1194 batches\n",
      "input image max pixel: 0.0582, ground truth image max pixel: 0.4450, reconstructed image max pixel: 0.1067\n",
      "[==============>...............] 620/1194 ( 51.9%) - ETA: 54.7m - train_loss: 0.0003                                   "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 58\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     45\u001b[0m     trainer \u001b[38;5;241m=\u001b[39m TorchTrainer(\n\u001b[1;32m     46\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     47\u001b[0m         optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m         scheduler_step_per_batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     56\u001b[0m     )\n\u001b[0;32m---> 58\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtraining\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# 4) save results\u001b[39;00m\n\u001b[1;32m     65\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_history(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpaths\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/history.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/XFlow/src/xflow/trainers/trainer.py:313\u001b[0m, in \u001b[0;36mTorchTrainer.fit\u001b[0;34m(self, epochs, train_loader, val_loader)\u001b[0m\n\u001b[1;32m    311\u001b[0m ctx\u001b[38;5;241m.\u001b[39mlogs \u001b[38;5;241m=\u001b[39m logs\n\u001b[1;32m    312\u001b[0m ctx\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m=\u001b[39m global_step\n\u001b[0;32m--> 313\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_batch_end\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# ---- scheduler per-batch (except Plateau) ----\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler_step_per_batch:\n",
      "File \u001b[0;32m~/Documents/GitHub/XFlow/src/xflow/trainers/trainer.py:62\u001b[0m, in \u001b[0;36mCallbackDispatcher.call\u001b[0;34m(self, name, ctx)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, ctx):\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m     kw \u001b[38;5;241m=\u001b[39m \u001b[43masdict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcbs:\n\u001b[1;32m     64\u001b[0m         fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(cb, name, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch/lib/python3.10/dataclasses.py:1238\u001b[0m, in \u001b[0;36masdict\u001b[0;34m(obj, dict_factory)\u001b[0m\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_dataclass_instance(obj):\n\u001b[1;32m   1237\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masdict() should be called on dataclass instances\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_asdict_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdict_factory\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch/lib/python3.10/dataclasses.py:1245\u001b[0m, in \u001b[0;36m_asdict_inner\u001b[0;34m(obj, dict_factory)\u001b[0m\n\u001b[1;32m   1243\u001b[0m result \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1244\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fields(obj):\n\u001b[0;32m-> 1245\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[43m_asdict_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdict_factory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1246\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend((f\u001b[38;5;241m.\u001b[39mname, value))\n\u001b[1;32m   1247\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dict_factory(result)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch/lib/python3.10/dataclasses.py:1279\u001b[0m, in \u001b[0;36m_asdict_inner\u001b[0;34m(obj, dict_factory)\u001b[0m\n\u001b[1;32m   1275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(obj)((_asdict_inner(k, dict_factory),\n\u001b[1;32m   1276\u001b[0m                       _asdict_inner(v, dict_factory))\n\u001b[1;32m   1277\u001b[0m                      \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mitems())\n\u001b[1;32m   1278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1279\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch/lib/python3.10/copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch/lib/python3.10/copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[0;32m--> 271\u001b[0m         state \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    273\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch/lib/python3.10/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch/lib/python3.10/copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch/lib/python3.10/copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch/lib/python3.10/copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[0;32m--> 271\u001b[0m         state \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    273\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch/lib/python3.10/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch/lib/python3.10/copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch/lib/python3.10/copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch/lib/python3.10/copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[0;32m--> 271\u001b[0m         state \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    273\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch/lib/python3.10/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch/lib/python3.10/copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch/lib/python3.10/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch/lib/python3.10/copy.py:211\u001b[0m, in \u001b[0;36m_deepcopy_tuple\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_deepcopy_tuple\u001b[39m(x, memo, deepcopy\u001b[38;5;241m=\u001b[39mdeepcopy):\n\u001b[0;32m--> 211\u001b[0m     y \u001b[38;5;241m=\u001b[39m [deepcopy(a, memo) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x]\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;66;03m# We're not going to put the tuple in the memo, but it's still important we\u001b[39;00m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# check for it, in case the tuple contains recursive mutable structures.\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch/lib/python3.10/copy.py:211\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_deepcopy_tuple\u001b[39m(x, memo, deepcopy\u001b[38;5;241m=\u001b[39mdeepcopy):\n\u001b[0;32m--> 211\u001b[0m     y \u001b[38;5;241m=\u001b[39m [\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x]\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;66;03m# We're not going to put the tuple in the memo, but it's still important we\u001b[39;00m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# check for it, in case the tuple contains recursive mutable structures.\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch/lib/python3.10/copy.py:153\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    151\u001b[0m copier \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__deepcopy__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     reductor \u001b[38;5;241m=\u001b[39m dispatch_table\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch/lib/python3.10/site-packages/torch/_tensor.py:121\u001b[0m, in \u001b[0;36mTensor.__deepcopy__\u001b[0;34m(self, memo)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    113\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe default implementation of __deepcopy__() for wrapper subclasses \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    114\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly works for subclass types that implement clone() and for which \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferent type.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    119\u001b[0m         )\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 121\u001b[0m     new_storage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_typed_storage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_deepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_quantized:\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;66;03m# quantizer_params can be different type based on torch attribute\u001b[39;00m\n\u001b[1;32m    124\u001b[0m         quantizer_params: Union[\n\u001b[1;32m    125\u001b[0m             Tuple[torch\u001b[38;5;241m.\u001b[39mqscheme, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m    126\u001b[0m             Tuple[torch\u001b[38;5;241m.\u001b[39mqscheme, Tensor, Tensor, \u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m    127\u001b[0m         ]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch/lib/python3.10/site-packages/torch/storage.py:1118\u001b[0m, in \u001b[0;36mTypedStorage._deepcopy\u001b[0;34m(self, memo)\u001b[0m\n\u001b[1;32m   1117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_deepcopy\u001b[39m(\u001b[38;5;28mself\u001b[39m, memo):\n\u001b[0;32m-> 1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_wrapped_storage(\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_untyped_storage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch/lib/python3.10/copy.py:153\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    151\u001b[0m copier \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__deepcopy__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     reductor \u001b[38;5;241m=\u001b[39m dispatch_table\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch/lib/python3.10/site-packages/torch/storage.py:231\u001b[0m, in \u001b[0;36m_StorageBase.__deepcopy__\u001b[0;34m(self, memo)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cdata \u001b[38;5;129;01min\u001b[39;00m memo:\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m memo[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cdata]\n\u001b[0;32m--> 231\u001b[0m new_storage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m memo[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cdata] \u001b[38;5;241m=\u001b[39m new_storage\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_storage\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch/lib/python3.10/site-packages/torch/storage.py:245\u001b[0m, in \u001b[0;36m_StorageBase.clone\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mclone\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    244\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a copy of this storage.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnbytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ==================== \n",
    "# Training\n",
    "# ====================\n",
    "from functools import partial\n",
    "\n",
    "from xflow import TorchTrainer, TorchGANTrainer\n",
    "from xflow.trainers import build_callbacks_from_config\n",
    "from xflow.extensions.physics.beam import extract_beam_parameters\n",
    "\n",
    "# 1) loss/optimizer\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# 2) callbacks (unchanged) + any custom wiring\n",
    "callbacks = build_callbacks_from_config(\n",
    "    config=config[\"callbacks\"],\n",
    "    framework=config[\"framework\"],  \n",
    ") # keep dataset closure for last callback, sequence hardcoded\n",
    "callbacks[-1].set_dataset(test_dataset)\n",
    "\n",
    "# Extract beam parameters closure (return as dict)\n",
    "if experiment_name in SAMPLE_FLATTENED:\n",
    "    extract_beam_parameters_dict = partial(extract_beam_parameters_flat, as_array=False)\n",
    "    beam_param_metric = make_beam_param_metric(extract_beam_parameters_dict)\n",
    "elif experiment_name in REGRESSION:   # e.g., \"ERN\"\n",
    "    beam_param_metric = make_param_metric()\n",
    "else:\n",
    "    extract_beam_parameters_dict = partial(extract_beam_parameters, as_array=False)\n",
    "    beam_param_metric = make_beam_param_metric(extract_beam_parameters_dict)\n",
    "\n",
    "# 3) run training\n",
    "if experiment_name in GAN:\n",
    "    trainer = TorchGANTrainer(\n",
    "        generator=G,\n",
    "        discriminator=D,\n",
    "        optimizer_g=opt_g,\n",
    "        optimizer_d=opt_d,\n",
    "        losses=losses,\n",
    "        device=device,\n",
    "        callbacks=callbacks,\n",
    "        output_dir=config[\"paths\"][\"output\"],\n",
    "        data_pipeline=train_dataset,\n",
    "        val_metrics=[beam_param_metric],\n",
    "    )\n",
    "else:\n",
    "    trainer = TorchTrainer(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        device=device,\n",
    "        callbacks=callbacks,\n",
    "        output_dir=config[\"paths\"][\"output\"],\n",
    "        data_pipeline=train_dataset,\n",
    "        val_metrics=[beam_param_metric],\n",
    "        scheduler= scheduler if experiment_name == \"SwinT\" else None, \n",
    "        scheduler_step_per_batch=True,\n",
    "    )\n",
    "\n",
    "history = trainer.fit(\n",
    "    train_loader=train_dataset, \n",
    "    val_loader=val_dataset,\n",
    "    epochs=config['training']['epochs'],\n",
    ")\n",
    "\n",
    "# 4) save results\n",
    "trainer.save_history(f\"{config['paths']['output']}/history.json\")\n",
    "trainer.save_model(config[\"paths\"][\"output\"])  # uses model.save_model(...) if available\n",
    "config_manager.save(output_dir=config[\"paths\"][\"output\"], config_filename=config[\"name\"])\n",
    "\n",
    "print(\"Training ALL complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
