{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "801323da",
   "metadata": {},
   "source": [
    "# Dataset Statistics/exploration\n",
    "\n",
    "Try to understand the quality of the data better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b4bc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "os.chdir(Path.cwd().parent)   # go one level up\n",
    "print(os.getcwd())         \n",
    "from functools import partial\n",
    "from xflow import SqlProvider, pipe_each, TransformRegistry as T\n",
    "from xflow.utils import plot_image\n",
    "import xflow.extensions.physics\n",
    "from config_utils import load_config, detect_machine\n",
    "from utils import *\n",
    "\n",
    "experiment_name = \"CAE_validate_clear\"  \n",
    "machine = detect_machine() \n",
    "\n",
    "config = load_config(\n",
    "    f\"{experiment_name}.yaml\",\n",
    "    machine=machine\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0ab52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to database and read image sample paths\n",
    "# \"\"\"wednesday chromox\"\"\"\n",
    "# dirs = config[\"paths\"][\"chromox_2025-11-19\"] \n",
    "# query = \"\"\"\n",
    "# SELECT \n",
    "#     image_path\n",
    "# FROM \n",
    "#     mmf_dataset_metadata \n",
    "# WHERE \n",
    "#     batch IN (10, 11, 12)\n",
    "# --LIMIT 20\n",
    "# \"\"\"\n",
    "\n",
    "\"\"\"Friday Chromox\"\"\"\n",
    "dirs = config[\"paths\"][\"chromox_2025-11-21\"] \n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    image_path\n",
    "FROM \n",
    "    mmf_dataset_metadata \n",
    "WHERE\n",
    "    batch IN (1, 2, 3)\n",
    "--LIMIT 20\n",
    "\"\"\"\n",
    "\n",
    "# \"\"\"Saturday Chromox\"\"\"\n",
    "# dirs = config[\"paths\"][\"chromox_2025-11-22-morning\"] \n",
    "# query = \"\"\"\n",
    "# SELECT \n",
    "#     image_path\n",
    "# FROM \n",
    "#     mmf_dataset_metadata \n",
    "# WHERE\n",
    "#     batch IN (10, 11, 12)\n",
    "# --LIMIT 20\n",
    "# \"\"\"\n",
    "\n",
    "db_path = f\"{dirs}/db/dataset_meta.db\"\n",
    "realbeam_provider = SqlProvider(\n",
    "    sources={\"connection\": db_path, \"sql\": query}, output_config={'list': \"image_path\"}\n",
    ")\n",
    "image_paths = realbeam_provider()\n",
    "print(f\"Found {len(image_paths)} entries in the database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198aa3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xflow.extensions.physics.beam import extract_beam_parameters\n",
    "params = {\n",
    "    \"crop_gt\": [[74, 728], [1158, 488]],\n",
    "    \"crop_fo\": [[360, 0], [1560, 1200]],\n",
    "    \"inp_size\": (256, 256),\n",
    "    \"out_size\": (256, 256),\n",
    "}\n",
    "\n",
    "def default_meta(path):\n",
    "    \"\"\"Default metadata extractor - path, filename, extension.\"\"\"\n",
    "    p = Path(path)\n",
    "    return {\"path\": str(p), \"filename\": p.stem, \"extension\": p.suffix}\n",
    "    \n",
    "extract_moments = partial(extract_beam_parameters, method=\"moments\")\n",
    "\n",
    "\n",
    "# Define transform pipeline\n",
    "transforms = [\n",
    "    partial(T.get(\"add_parent_dir\"), parent_dir=dirs),\n",
    "    partial(T.get(\"torch_load_image_with_meta\"), meta_fn=default_meta),\n",
    "    # [None, T.get(\"debug_print\")], \n",
    "    [T.get(\"torch_to_tensor\"), None],  \n",
    "    [T.get(\"torch_to_grayscale\"), None],\n",
    "    [T.get(\"torch_remap_range\"), None],\n",
    "    [partial(T.get(\"torch_split_width\"), swap=True), None],    # (fiber_output, ground_truth)\n",
    "    # [\n",
    "    #     partial(T.get(\"torch_crop_area\"), points=params[\"crop_fo\"]),\n",
    "    #     partial(T.get(\"torch_crop_area\"), points=params[\"crop_gt\"]),\n",
    "    # ],\n",
    "    [\n",
    "        partial(T.get(\"torch_resize\"), size=params[\"inp_size\"]),\n",
    "        partial(T.get(\"torch_resize\"), size=params[\"out_size\"]),\n",
    "        None\n",
    "    ],\n",
    "    # [\n",
    "    #     T.get(\"discard\"),\n",
    "    #     partial(T.get(\"apply\"), fn=extract_moments)\n",
    "    # ],\n",
    "    # T.get(\"flatten_nested\"),\n",
    "    # T.get(\"collect\"),\n",
    "    T.get(\"raise_if_none\"),\n",
    "    T.get(\"join_image\"),\n",
    "    T.get(\"save_image_from_meta\"),\n",
    "]\n",
    "\n",
    "results = list(pipe_each(\n",
    "    image_paths,\n",
    "    *transforms,\n",
    "    progress=True,\n",
    "    desc=\"Processing images\",\n",
    "    skip_errors=True,\n",
    "))\n",
    "print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec212f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image(results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7da7aac",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1277340a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xflow.utils.visualization import stack_log_remap, stack_linear_clip\n",
    "stacked = stack_log_remap([x[1] for x in results])\n",
    "plot_image(stacked)\n",
    "\n",
    "stacked = stack_linear_clip([x[1] for x in results])\n",
    "plot_image(stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7ea080",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Tuple, Optional\n",
    "import numpy as np\n",
    "\n",
    "Point = Tuple[float, float]\n",
    "\n",
    "\n",
    "def _min_mass_segment(weights: np.ndarray, frac: float, eps: float = 1e-12) -> Tuple[int, int]:\n",
    "    \"\"\"\n",
    "    Smallest contiguous index range [i, j) whose sum >= frac * total.\n",
    "    Returns (i, j) with j exclusive.\n",
    "    \"\"\"\n",
    "    w = np.asarray(weights, dtype=float)\n",
    "    w = np.clip(w, 0.0, None)\n",
    "    n = w.size\n",
    "    if n == 0:\n",
    "        raise ValueError(\"Empty weights.\")\n",
    "    total = float(w.sum())\n",
    "    if total <= eps:\n",
    "        # No mass -> return full range\n",
    "        return 0, n\n",
    "\n",
    "    target = frac * total\n",
    "    best_i, best_j = 0, n\n",
    "    best_len = n + 1\n",
    "\n",
    "    j = 0\n",
    "    s = 0.0\n",
    "    for i in range(n):\n",
    "        while j < n and s < target:\n",
    "            s += w[j]\n",
    "            j += 1\n",
    "        if s >= target:\n",
    "            if (j - i) < best_len:\n",
    "                best_len = j - i\n",
    "                best_i, best_j = i, j\n",
    "        s -= w[i]\n",
    "\n",
    "    return best_i, best_j\n",
    "\n",
    "\n",
    "def _clamp_interval(a: float, b: float, lo: float = 0.0, hi: float = 1.0) -> Tuple[float, float]:\n",
    "    \"\"\"Clamp [a,b] into [lo,hi] by shifting (keeps length if possible).\"\"\"\n",
    "    length = b - a\n",
    "    if length >= (hi - lo):\n",
    "        return lo, hi\n",
    "    if a < lo:\n",
    "        b = b + (lo - a)\n",
    "        a = lo\n",
    "    if b > hi:\n",
    "        a = a - (b - hi)\n",
    "        b = hi\n",
    "    a = max(lo, a)\n",
    "    b = min(hi, b)\n",
    "    return a, b\n",
    "\n",
    "\n",
    "def square_from_projections(\n",
    "    img: np.ndarray,\n",
    "    frac: float,\n",
    "    *,\n",
    "    make_square: bool = True,\n",
    "    channel_reduce: str = \"sum\",  # \"sum\" or \"mean\"\n",
    "    eps: float = 1e-12,\n",
    ") -> Tuple[Point, Point]:\n",
    "    \"\"\"\n",
    "    1) Project image onto x and y by summing pixels.\n",
    "    2) Find minimal contiguous x-interval containing `frac` of x-projection mass,\n",
    "       and same for y.\n",
    "    3) Form rectangle. If make_square=True, expand to the smallest axis-aligned square\n",
    "       that contains that rectangle (centered), clamped to [0,1].\n",
    "\n",
    "    Returns (top_left, bottom_right) in normalized coords, with (0,0) at top-left.\n",
    "    \"\"\"\n",
    "    if frac > 1.0:\n",
    "        frac = frac / 100.0\n",
    "    if not (0.0 < frac <= 1.0):\n",
    "        raise ValueError(\"frac must be in (0,1] or (0,100].\")\n",
    "\n",
    "    a = np.asarray(img, dtype=float)\n",
    "    if a.ndim == 3:\n",
    "        if channel_reduce == \"mean\":\n",
    "            a = a.mean(axis=2)\n",
    "        elif channel_reduce == \"sum\":\n",
    "            a = a.sum(axis=2)\n",
    "        else:\n",
    "            raise ValueError(\"channel_reduce must be 'sum' or 'mean'\")\n",
    "    elif a.ndim != 2:\n",
    "        raise ValueError(\"img must be 2D or 3D array\")\n",
    "\n",
    "    # Ensure non-negative \"mass\"\n",
    "    a = np.clip(a, 0.0, None)\n",
    "\n",
    "    H, W = a.shape\n",
    "    if H == 0 or W == 0:\n",
    "        raise ValueError(\"img has zero size\")\n",
    "\n",
    "    proj_x = a.sum(axis=0)  # length W\n",
    "    proj_y = a.sum(axis=1)  # length H\n",
    "\n",
    "    ix0, ix1 = _min_mass_segment(proj_x, frac, eps=eps)  # [ix0, ix1)\n",
    "    iy0, iy1 = _min_mass_segment(proj_y, frac, eps=eps)  # [iy0, iy1)\n",
    "\n",
    "    # Convert pixel-edge indices to normalized [0,1]\n",
    "    x0, x1 = ix0 / W, ix1 / W\n",
    "    y0, y1 = iy0 / H, iy1 / H\n",
    "\n",
    "    if not make_square:\n",
    "        return (x0, y0), (x1, y1)\n",
    "\n",
    "    # Expand rectangle to a square (axis-aligned), centered on the rectangle\n",
    "    w = x1 - x0\n",
    "    h = y1 - y0\n",
    "    side = max(w, h)\n",
    "\n",
    "    cx = 0.5 * (x0 + x1)\n",
    "    cy = 0.5 * (y0 + y1)\n",
    "\n",
    "    sx0, sx1 = cx - 0.5 * side, cx + 0.5 * side\n",
    "    sy0, sy1 = cy - 0.5 * side, cy + 0.5 * side\n",
    "\n",
    "    sx0, sx1 = _clamp_interval(sx0, sx1, 0.0, 1.0)\n",
    "    sy0, sy1 = _clamp_interval(sy0, sy1, 0.0, 1.0)\n",
    "\n",
    "    return (sx0, sy0), (sx1, sy1)\n",
    "\n",
    "\n",
    "# Example:\n",
    "tl, br = square_from_projections(stacked, 0.96)\n",
    "highlighted = draw_red_square(stacked, tl, br, thickness=2)\n",
    "plot_image(highlighted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7d73cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl, br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b1ab38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "a = np.array(results)\n",
    "hc, vc, hw, vw = a[:, 0], a[:, 1], a[:, 2], a[:, 3]\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 4), constrained_layout=True)\n",
    "\n",
    "ax[0].scatter(hc, vc, s=5, alpha=0.3)\n",
    "ax[0].set(xlim=(0, 1), ylim=(0, 1), xlabel=\"h_centroid\", ylabel=\"v_centroid\", title=\"Centroids\")\n",
    "ax[0].set_aspect(\"equal\")\n",
    "\n",
    "ax[1].scatter(hw, vw, s=5, alpha=0.3)\n",
    "ax[1].set(xlim=(0, 1), ylim=(0, 1), xlabel=\"h_width\", ylabel=\"v_width\", title=\"Widths\")\n",
    "ax[1].set_aspect(\"equal\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
