# ====================
# U-Net fiber image reconstruction configuration file
# ====================

seed: &seed 42
name: &config "U_Net.yaml"
framework: "pytorch"

paths:
  output:  ${paths.output_root}           # comes from shared defaults
  dataset: ${paths.datasets.mmf}          # picked by machine profile

training:
  epochs: &epochs 100                     # Number of full passes over training data
  learning_rate: 1.0e-4                   # Initial learning rate for optimizer
  batch_size: &batch 16                   # Number of samples per gradient update

model:
  in_channels: 1                          # input channels (1=grayscale, 3=RGB, etc.)
  out_channels: 1                         # output channels (e.g., 1 for regression/map)
  enc_channels: [64, 128, 256]   # encoder widths at each downsampling step   [32, 64, 128, 256, 512]
  dec_channels: [64, 128, 256]   # decoder widths at each upsampling step
  bottleneck_channels: 512               # channels at the bottleneck (deepest layer)
  use_skips: False
  use_batchnorm: True
  act: "leaky_relu"
  use_sigmoid: False

data:
  subsample_fraction: 1                   # Total fraction of data to use, 1 for full set
  train_val_split: 0.8                    # Train/validation split ratio
  val_test_split: 0.5                     # Validation/test split ratio
  input_shape: &inp [256, 256]       # Speckle image dimensions [H, W]
  output_shape: &out [256, 256]            # Input pattern size [H, W]
  transforms:
    torch:
      - name: "torch_load_image"          # Image loading transform
      - name: "torch_to_tensor"           # Convert to tensor
      - name: "torch_to_grayscale"        # Convert to grayscale
      - name: "torch_remap_range"         # Normalize pixel values to [0,1]
      - name: "torch_split_width"         # Split image into left/right halves
        params:
          swap: True                     # Swap left/right halves
      - name: "multi_transform"           # take the left/right and apply transforms in sequence order
        params:
          transforms:
            - name: "torch_resize"        # Resize image to match 
              params:
                size: *inp                # Resize dimensions [H, W]
            - name: "torch_resize"        # Resize image to match 
              params:
                size: *out                # Resize dimensions [H, W]
  dataset_ops:                            # Dataset level operations
    - name: "torch_batch"                 # Batch images
      params:
        batch_size: *batch                # Number of images per batch
        shuffle: True                     # Shuffle dataset
        num_workers: 0                    # Number of worker threads for data loading
        prefetch_factor: 2                # Number of batches to prefetch
        seed: *seed 

callbacks:
  - name: "torch_batch_progress_bar"
    params:
      only_keys: ["train_loss", "val_loss"]
  - name: "torch_early_stopping"          # Factory key for early stopping
    params:
      monitor: "val_loss"                 # Metric to monitor
      patience: 20                        # Epochs to wait before stopping
  - name: "torch_image_reconstruction_callback"
    params:
      save_dir: ${paths.output}           # Directory to save results

extra_files: ["models/U_Net.py"]