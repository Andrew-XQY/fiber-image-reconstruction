{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59e53431-2147-4fec-ab30-559fb2aa5ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[config_utils] Using machine profile: mac-andrewxu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'paths': {'project_root': '.',\n",
       "  'datasets': {'mmf': '/Users/andrewxu/Documents/DataHub/local_images/MMF',\n",
       "   'syns': '/Users/andrewxu/Documents/DataHub/datasets/2024-08-15/dataset/1'},\n",
       "  'output_root': './results/CAE-20251023120443',\n",
       "  'output': './results/CAE-20251023120443',\n",
       "  'dataset': '/Users/andrewxu/Documents/DataHub/local_images/MMF'},\n",
       " 'seed': 500,\n",
       " 'name': 'CAE.yaml',\n",
       " 'framework': 'pytorch',\n",
       " 'model': {'in_channels': 1,\n",
       "  'out_channels': 1,\n",
       "  'kernel_size': 4,\n",
       "  'encoder': [64, 128, 128, 256, 512, 512],\n",
       "  'decoder': [512, 512, 256, 128, 128, 64],\n",
       "  'apply_batchnorm': [0, 1, 1, 1, 1, 1],\n",
       "  'apply_dropout': [1, 1, 0, 0, 0, 0],\n",
       "  'final_activation': 'sigmoid'},\n",
       " 'training': {'epochs': 100, 'learning_rate': 0.0001, 'batch_size': 32},\n",
       " 'callbacks': [{'name': 'torch_batch_progress_bar',\n",
       "   'params': {'only_keys': ['train_loss', 'val_loss']}},\n",
       "  {'name': 'torch_early_stopping',\n",
       "   'params': {'monitor': 'val_loss', 'patience': 20}},\n",
       "  {'name': 'torch_image_reconstruction_callback',\n",
       "   'params': {'save_dir': './results/CAE-20251023120443'}}],\n",
       " 'data': {'subsample_fraction': 1,\n",
       "  'training_set': 'procIMGs/raw/',\n",
       "  'evaluation_set': 'procIMGs_2/raw/',\n",
       "  'train_val_split': 0.8,\n",
       "  'val_test_split': 0.5,\n",
       "  'input_shape': [256, 256],\n",
       "  'output_shape': [256, 256],\n",
       "  'transforms': {'torch': [{'name': 'torch_load_image'},\n",
       "    {'name': 'torch_to_tensor'},\n",
       "    {'name': 'torch_to_grayscale'},\n",
       "    {'name': 'torch_remap_range'},\n",
       "    {'name': 'torch_split_width', 'params': {'swap': True}},\n",
       "    {'name': 'multi_transform',\n",
       "     'params': {'transforms': [{'name': 'torch_resize',\n",
       "        'params': {'size': [256, 256]}},\n",
       "       {'name': 'torch_resize', 'params': {'size': [256, 256]}}]}}]},\n",
       "  'dataset_ops': [{'name': 'torch_batch',\n",
       "    'params': {'batch_size': 32,\n",
       "     'shuffle': True,\n",
       "     'num_workers': 0,\n",
       "     'prefetch_factor': 2,\n",
       "     'seed': 500}}]},\n",
       " 'extra_files': ['models/CAE.py']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install xflow-py\n",
    "from xflow import ConfigManager, FileProvider, PyTorchPipeline, show_model_info\n",
    "from xflow.data import build_transforms_from_config\n",
    "from xflow.utils import load_validated_config, save_image\n",
    "import xflow.extensions.physics\n",
    "\n",
    "import torch\n",
    "import os\n",
    "\n",
    "os.chdir('..')\n",
    "from datetime import datetime  \n",
    "from config_utils import load_config\n",
    "from utils import *\n",
    "\n",
    "\n",
    "# ==================== \n",
    "# Configuration\n",
    "# ==================== \n",
    "\n",
    "# Create experiment output directory  (timestamped)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")  \n",
    "\n",
    "experiment_name = \"CAE\"  # TM, SHL_DNN, U_Net, Pix2pix, ERN, CAE, SwinT, CAE_syth\n",
    "config_manager = ConfigManager(load_config(f\"{experiment_name}.yaml\"))\n",
    "config = config_manager.get()\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d22475be-325b-411f-84cd-10b27038015c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples:  5200 549 549\n",
      "Batch:  163 18 18\n",
      "Batch shapes: torch.Size([32, 1, 256, 256]), torch.Size([32, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# ==================== \n",
    "# Prepare Dataset\n",
    "# ====================\n",
    "training_folder = os.path.join(config[\"paths\"][\"dataset\"], config[\"data\"][\"training_set\"])\n",
    "evaluation_folder = os.path.join(config[\"paths\"][\"dataset\"], config[\"data\"][\"evaluation_set\"])\n",
    "train_provider = FileProvider(training_folder).subsample(fraction=config[\"data\"][\"subsample_fraction\"], seed=config[\"seed\"]) \n",
    "evaluation_provider = FileProvider(evaluation_folder).subsample(fraction=config[\"data\"][\"subsample_fraction\"], seed=config[\"seed\"]) \n",
    "val_provider, test_provider = evaluation_provider.split(ratio=config[\"data\"][\"val_test_split\"], seed=config[\"seed\"])\n",
    "\n",
    "transforms = build_transforms_from_config(config[\"data\"][\"transforms\"][\"torch\"])\n",
    "def make_dataset(provider):\n",
    "    return PyTorchPipeline(provider, transforms).to_memory_dataset(config[\"data\"][\"dataset_ops\"])\n",
    "\n",
    "train_dataset = make_dataset(train_provider)\n",
    "val_dataset = make_dataset(val_provider)\n",
    "test_dataset = make_dataset(test_provider)\n",
    "\n",
    "print(\"Samples: \",len(train_provider),len(val_provider),len(test_provider))\n",
    "print(\"Batch: \",len(train_dataset),len(val_dataset),len(test_dataset))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
